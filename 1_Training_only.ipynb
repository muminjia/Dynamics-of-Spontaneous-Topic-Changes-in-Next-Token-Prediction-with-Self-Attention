{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csYaLOcKmUZH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import copy\n",
        "import math\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy.linalg as npl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import json\n",
        "from sklearn.svm import LinearSVC\n",
        "from collections import defaultdict\n",
        "import cvxpy as cp\n",
        "from data_utils_m import *\n",
        "from nxt_token_solver_m import W_svm_solver_cvxpy, R_solver, Tarjan\n",
        "from itertools import zip_longest\n",
        "\n",
        "from base_nonlinear import MLayerAttn\n",
        "from utils import *\n",
        "from train_utils_m import train_W, train_Wfin\n",
        "from visualizer import show_corr, show_norm_diff, show_proj_corr, show_attn_probs, show_attn_probs_neg\n",
        "\n",
        "import time\n",
        "from google.colab import files\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJimz58Ne3Bj"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjKghJhTC_qU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1. numeric settings\n",
        "\"\"\"\n",
        "K = 7  # Vocabulary size\n",
        "L = 8  # Number of arrows to randomly choose\n",
        "T = 4 # the length of sequence (not include the next token)\n",
        "n = 10 # Number of sequence in each dataset\n",
        "d = 4 # dim of embedding token\n",
        "\n",
        "\"\"\"\n",
        "2. data parameters\n",
        "\"\"\"\n",
        "token_choice = 'random' # ['equi-corr', 'ortho', 'random']\n",
        "cls_choice = 'iden'\n",
        "same_last_token = False\n",
        "rep_seq = False\n",
        "check_label = True\n",
        "check_asyc = False\n",
        "\n",
        "toy_case = False\n",
        "batch_toy = False\n",
        "custom_initialize = False\n",
        "\n",
        "separa = False # Whether the last token can map to different labels\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "3. attention model parameters\n",
        "\"\"\"\n",
        "loss_type = 'nll' # ['ce', 'nll', 'corr', 'lsq2', 'mse']\n",
        "\n",
        "nlayer = 1 # number of layers\n",
        "\n",
        "skip = False # add skip connection to every attention output\n",
        "layer_norm = False # add layer norm to every attention output\n",
        "avg_norm = False\n",
        "factorize_w = False # use W or (Q, K)\n",
        "\n",
        "initialize_w = 'default' # 'default': random initialization, 'zero': initialize W as zero matrix, 'random': random initialization with varying variance\n",
        "strong_default = False\n",
        "initialize_wfin = 'zero'\n",
        "\n",
        "reg_wfin = 0 # regularization for W_fin\n",
        "# W_fin must be initialized as zero matrix\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "epochs = 1\n",
        "ITN = 6000\n",
        "\n",
        "norm_grad = True\n",
        "\n",
        "Wi_list = np.zeros((nlayer, ITN, d, d))\n",
        "sol_cvx_list = np.zeros((nlayer, d, d))\n",
        "Wi_norm_list = np.zeros((nlayer, epochs, ITN))\n",
        "\n",
        "dlist = [8]\n",
        "\n",
        "attn_probs = np.zeros((len(dlist), epochs, ITN))\n",
        "corr_list = np.zeros((len(dlist), 2, epochs, ITN))\n",
        "\n",
        "\"\"\"\n",
        "customize_seed\n",
        "\"\"\"\n",
        "def customize_seed(seed): # {topic 1: seed = 42, topic 2: seed = 99, combine: seed = 22}\n",
        "    random.seed(seed) # select_arrows_for_each_token() and find_and_add_missing_relationships()\n",
        "    np.random.seed(seed) # step 2.3 of generate_sequence_from_tpgs()\n",
        "    torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyR-0mFIl9p0"
      },
      "source": [
        "## Part 1: Generate Theoretical TPGs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxr6aDZy3LeW"
      },
      "source": [
        "### Step 1. Define K and L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qg4sTaV3ctJ"
      },
      "source": [
        "### Step 2. Randomly choose  𝐿  (# of arrows) couples for each token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmpsDDaS3cYx"
      },
      "outputs": [],
      "source": [
        "# For each token k = 1, 2, ..., K, randomly select L arrows involving k\n",
        "def select_arrows_for_each_token(K, L):\n",
        "\n",
        "    # Get all possible directed edges (ei -> ej where ei != ej)\n",
        "    all_possible_edges = [(i, j) for i, j in itertools.permutations(range(K), 2)]\n",
        "\n",
        "    initial_tpgs = {}\n",
        "\n",
        "    for k in range(K):\n",
        "        # Select edges where token k is involved (either as the source or destination)\n",
        "        valid_edges = [edge for edge in all_possible_edges if edge[0] == k or edge[1] == k]\n",
        "\n",
        "        # Ensure that token k is included in the TPG\n",
        "        selected_edges = random.sample(valid_edges, 1)  # Pick one edge that includes token k\n",
        "\n",
        "        # Now pick the rest of the L-1 arrows from all possible edges (can include or exclude token k)\n",
        "        other_edges = [edge for edge in all_possible_edges if edge not in selected_edges]\n",
        "        selected_edges += random.sample(other_edges, L - 1)  # Pick (L-1) arrows randomly\n",
        "\n",
        "        initial_tpgs[k] = selected_edges\n",
        "    return initial_tpgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xObHf2-mL_23"
      },
      "source": [
        "### Step 3. Add missing arrows from token k to all tokens based on its own TPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzhKihK0ZZ1X"
      },
      "outputs": [],
      "source": [
        "def forcing_reached_by_k(k, initial_tpgs):\n",
        "\n",
        "    initial_tpg_k = initial_tpgs[k]\n",
        "    theor_tpg_k = initial_tpg_k.copy()\n",
        "\n",
        "    # Step 1: find all unique tokens in tpg(k)\n",
        "    unique_tokens = {arrow[0] for arrow in initial_tpg_k}.union({arrow[1] for arrow in initial_tpg_k})\n",
        "\n",
        "    # Step 2: determine tokens that are not reached by the token k\n",
        "    reachable_tokens = {arrow[1] for arrow in initial_tpg_k if arrow[0] == k}  # Tokens the key currently points to\n",
        "    missing_tokens = unique_tokens - reachable_tokens - {k}  # Exclude the key itself\n",
        "\n",
        "    # Step 3: add missing arrows from `k` to ensure reachability to all tokens in unique_tokens\n",
        "    new_arrows = [(k, target) for target in missing_tokens]\n",
        "    theor_tpg_k.extend(new_arrows)\n",
        "\n",
        "    return theor_tpg_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VncP2eahZ8Hu"
      },
      "source": [
        "### Step 4.Theoretical TPGs based on Step 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vYv8keQZ7lq"
      },
      "outputs": [],
      "source": [
        "def get_theor_tpgs_new(K, L):\n",
        "\n",
        "    theor_tpgs = {k:[] for k in range(K)} # save the theoretical TPGs\n",
        "    theor_Gs = {k: nx.DiGraph() for k in range(K)} # save the theoretical TPG graph\n",
        "\n",
        "    initial_tpgs = select_arrows_for_each_token(K,L) # randomly select L arrows out of K(K-1)\n",
        "\n",
        "    for k in range(K):\n",
        "        theor_tpg_k = forcing_reached_by_k(k, initial_tpgs)\n",
        "        theor_tpgs[k] = theor_tpg_k\n",
        "\n",
        "        for i in range(len(theor_tpg_k)):\n",
        "            edge = theor_tpg_k[i]\n",
        "            theor_Gs[k].add_edge(edge[0], edge[1])\n",
        "\n",
        "    return initial_tpgs, theor_tpgs, theor_Gs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbtK0o8ULstQ"
      },
      "outputs": [],
      "source": [
        "# For TPGs visualization if needed\n",
        "def draw_graphs(k, Graphs, topic, TPG_type): # k = token ID\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    pos = nx.spring_layout(Graphs)  # Position nodes using the spring layout\n",
        "\n",
        "    nx.draw(Graphs[k], pos, with_labels=True, arrows=True, node_size=500, node_color='lightblue', font_size=7, font_weight='bold')\n",
        "    plt.title(f'{topic} {TPG_type}: Token {k}')\n",
        "    plt.grid(False)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbvb5PUYMIC-"
      },
      "source": [
        "### Step 5. Generate TPG combining two topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDMjN3g9MRGx"
      },
      "outputs": [],
      "source": [
        "# Combine two TPGs for each token\n",
        "def combine_tpgs(tpgs_group_1, tpgs_group_2):\n",
        "    combined_tpgs = {}\n",
        "    for k in range(K):\n",
        "        combined_tpgs[k] = tpgs_group_1[k] + [edge for edge in tpgs_group_2[k] if edge not in tpgs_group_1[k]]\n",
        "\n",
        "    return combined_tpgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioCznARukful"
      },
      "outputs": [],
      "source": [
        "# Generate theoretical tpgs for the combination of two topics\n",
        "def get_theor_tpgs_cb_new(theor_tpgs_1, theor_tpgs_2):\n",
        "\n",
        "    theor_tpgs = {k:[] for k in range(K)} # save the theoretical TPGs\n",
        "    theor_Gs = {k: nx.DiGraph() for k in range(K)} # save the theoretical TPG graph\n",
        "\n",
        "    initial_tpgs = combine_tpgs(theor_tpgs_1, theor_tpgs_2)\n",
        "\n",
        "    for k in range(K):\n",
        "        theor_tpg_k = forcing_reached_by_k(k, initial_tpgs)\n",
        "        theor_tpgs[k] = theor_tpg_k\n",
        "\n",
        "        for i in range(len(theor_tpg_k)):\n",
        "            edge = theor_tpg_k[i]\n",
        "            theor_Gs[k].add_edge(edge[0], edge[1])\n",
        "\n",
        "    return initial_tpgs, theor_tpgs, theor_Gs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrO9O_AbBaLw"
      },
      "source": [
        "## Part 2: Generate data for each topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1nv7ZHfy6bR"
      },
      "source": [
        "### Step 6. Decide the length of sequence T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJflKLzgzY-w"
      },
      "source": [
        "### Step 7. Generate sequence for each topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFfBECjJzX5z"
      },
      "outputs": [],
      "source": [
        "def generate_sequence_from_tpgs(theor_tpgs, T):\n",
        "    sequence_length = T  # Sequence length is T = 4\n",
        "\n",
        "    # Step 1: Randomly choose the last token k (e_T)\n",
        "    last_token_k = random.randint(0, K-1)  # Choose a random token as the last one (0 <= k <= K-1)\n",
        "\n",
        "    tpg_for_k = theor_tpgs[last_token_k]  # Select the TPG for the last token k\n",
        "\n",
        "\n",
        "    # Step 2: Randomly choose the next token e_{T+1} in the selected TPG\n",
        "    ## 2.1 find e_j that have arrows coming from the last token k\n",
        "    outgoing_edges = [edge for edge in tpg_for_k if edge[0] == last_token_k]\n",
        "    destination_nodes = [edge[1] for edge in outgoing_edges]\n",
        "    destination_nodes.append(last_token_k)\n",
        "\n",
        "    ## 2.2 count the arrows pointing to each destination node (include e_j itself)\n",
        "    destination_counts = {node: 1 for node in destination_nodes} # start from 1: including e_j itself\n",
        "    for edge in tpg_for_k:\n",
        "        if edge[1] in destination_counts:\n",
        "            destination_counts[edge[1]] += 1\n",
        "\n",
        "    ## 2.3 randomly choose the next token e_{T+1} based on weighted prob\n",
        "    total_count = sum(destination_counts.values())\n",
        "    prob = [count / total_count for count in destination_counts.values()]\n",
        "\n",
        "    next_token = np.random.choice(list(destination_counts.keys()), p=prob)\n",
        "\n",
        "\n",
        "    # Step 3: Randomly choose the location of the next token in the input sequence\n",
        "    available_positions = list(range(sequence_length - 1))  # Positions: 0, 1, 2, 3\n",
        "    next_token_position_input = random.choice(available_positions)  # Choose a position for e_{T+1}\n",
        "\n",
        "    input_sequence = [None] * (sequence_length - 1) # Initialize the input sequence with None\n",
        "    input_sequence.append(last_token_k)\n",
        "    input_sequence[next_token_position_input] = next_token  # Place e_{T+1} in the sequence\n",
        "\n",
        "\n",
        "    # Step 4: Randomly choose the rest of the tokens that have arrows to the next token in the TPG\n",
        "    remaining_positions = [pos for pos in available_positions if pos != next_token_position_input]\n",
        "\n",
        "    # Find tokens that have arrows pointing to the chosen next token\n",
        "    possible_previous_tokens = [edge[0] for edge in tpg_for_k if edge[1] == next_token]\n",
        "    possible_previous_tokens.append(next_token) # next_token can also be chosen as the rest of token\n",
        "\n",
        "    if len(possible_previous_tokens) == 0:\n",
        "        raise ValueError(f\"No available nodes in the TPG for token {last_token_k}.\")\n",
        "\n",
        "    # Randomly choose tokens for the remaining positions\n",
        "    for pos in remaining_positions:\n",
        "        token = random.choice(possible_previous_tokens)\n",
        "        input_sequence[pos] = token\n",
        "\n",
        "    return input_sequence, next_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqKHeGRIF4xj"
      },
      "source": [
        "### Step 8. Repeat $n$ times to generate data for topic 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaUB4iPk8tBT"
      },
      "outputs": [],
      "source": [
        "# Generate data set with N sequences based on the updated TPG\n",
        "def generate_data(theor_tpgs, n, T):\n",
        "\n",
        "    results = []\n",
        "    for i in range(n):\n",
        "        sequence, next_token = generate_sequence_from_tpgs(theor_tpgs, T)\n",
        "        results.append((sequence, next_token))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dnf3SZFf60"
      },
      "source": [
        "### Step 9. Generate data for topic 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atkV5hsTT70n"
      },
      "source": [
        "### Step 10. Get the dataset for combining two topics\n",
        "Simply union data_1 and data_2\n",
        "```\n",
        "data_combine = data_topic_1 + data_topic_2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtUrPNMISGZ5"
      },
      "source": [
        "### NOTE: Get empirical tpgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYPmeI4NPyFw"
      },
      "outputs": [],
      "source": [
        "def get_empir_tpgs(empir_data):\n",
        "    seq_classified = {k: [] for k in range(K)}  # save the data group by the last token ID\n",
        "\n",
        "    empir_tpgs = {k:[] for k in range(K)} # save the edges based on the generated data\n",
        "    empir_Gs = {k: nx.DiGraph() for k in range(K)} # save the empirical TPG\n",
        "\n",
        "    for seq in empir_data:\n",
        "        k = seq[0][-1]\n",
        "        seq_classified[k].append(seq)\n",
        "\n",
        "    for k, seqs in seq_classified.items():\n",
        "        for seq in seqs:\n",
        "            tokens = seq[0]\n",
        "            for i in range (len(tokens)):\n",
        "                if tokens[i] != seq[-1]:\n",
        "                    edge = (tokens[i], seq[-1])\n",
        "                    if edge not in empir_tpgs[k]:\n",
        "                        empir_tpgs[k].append(edge) # from every input token to the next token\n",
        "                        empir_Gs[k].add_edge(tokens[i], seq[-1])\n",
        "    return seq_classified, empir_tpgs, empir_Gs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z_qXK8dTc3m"
      },
      "source": [
        "## Part 3: Calculate $W^{svm}$ and $W(\\tau)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWJCNgSesfeZ"
      },
      "source": [
        "### Step 11. Calculate $W_1^{svm}, W_2^{svm}, W^{svm}$ by using $\\{X^1_i, y^1_i\\}_{i=1}^N$, $\\{X^2_i, y^2_i\\}_{i=1}^N$, and $\\{X_i, y_i\\}_{i=1}^N$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3f8ohSvuuSn"
      },
      "source": [
        "#### 11.1 Get vocabulary and dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9YD5BxCPPlI"
      },
      "outputs": [],
      "source": [
        "def get_vocab_dict(token_choice, K, d, rho = 0.5):\n",
        "\n",
        "    if token_choice == 'ortho':\n",
        "\n",
        "        assert K <= d\n",
        "\n",
        "        A = torch.randn(d, d).double()\n",
        "\n",
        "        Vocab = torch.linalg.qr(A.T)[0][:K] # [K, d]\n",
        "\n",
        "        tolerance = 1e-6  # Adjust as needed for your precision requirements\n",
        "\n",
        "        for i in range(K):\n",
        "            for j in range(i + 1, K):\n",
        "                dot_product = torch.dot(Vocab[i], Vocab[j]).item()\n",
        "                if abs(dot_product) < tolerance:\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"Dot product of row {i} and row {j}: {dot_product} (not within tolerance)\")\n",
        "\n",
        "    elif token_choice == 'equi-corr':\n",
        "        # Generate a set of K - 1 vectors with correlation rho\n",
        "        A = torch.randn(d, d).double()\n",
        "        C = torch.linalg.qr(A)[0][:K] # [K, d]\n",
        "        Vocab = torch.zeros((K - 1, d)).double()\n",
        "        for i in range(0, K - 1):\n",
        "            Vocab[i] = math.sqrt(rho) * C[0] + math.sqrt(1 - rho) * C[i + 1]\n",
        "\n",
        "        for i in range(K - 1):\n",
        "            assert Vocab[i].norm() - 1 < 1e-5\n",
        "            for j in range(i + 1, K - 1):\n",
        "                # Calculate the correlation between Vocab[i] and Vocab[j]\n",
        "                assert torch.abs(Vocab[i].dot(Vocab[j])) - rho < 1e-5\n",
        "        K = K - 1\n",
        "    else:\n",
        "        Vocab = torch.randn(K, d).double()\n",
        "        Vocab = torch.nn.functional.normalize(Vocab, dim = -1)\n",
        "    dict_token = {i: Vocab[i] for i in range(K)} # used to find the index of the token\n",
        "\n",
        "    EE_T_inv = torch.inverse(Vocab @ Vocab.T) # shape [K,K]\n",
        "    pseudo_Vocab = (Vocab.T @ EE_T_inv).T\n",
        "\n",
        "\n",
        "    return Vocab, dict_token, pseudo_Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25FG0AFHu1gS"
      },
      "source": [
        "#### 11.2 Get other input parameters\n",
        "- Part 1: X\n",
        "- Part 2: idx_token\n",
        "- Part 3: idx_z\n",
        "- Part 4: C_alpha\n",
        "- Part 5: scc_klst\n",
        "- Part 6: z, the last token of each sequence\n",
        "- Part 7: get adj_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFguuQFycg43"
      },
      "outputs": [],
      "source": [
        "# Part 1: X, embedding word for each sequence\n",
        "def get_X(data, dict_token):\n",
        "\n",
        "      input_X = []\n",
        "\n",
        "      for item in data:\n",
        "          key_sequence = item[0]  # Extract the token ID in each sequence\n",
        "          values = [dict_token[key].tolist() for key in key_sequence]  # Get the corresponding values from dict_token\n",
        "          input_X.append(values)\n",
        "\n",
        "      input_X = torch.tensor(input_X)\n",
        "      X = input_X.double() #dtype: torch.float64\n",
        "      return X\n",
        "\n",
        "# Part 2: idx_token, token ID for each input sequence\n",
        "def get_idx_token(data):\n",
        "\n",
        "    data_input_idx = [item[0] for item in data] # extract id of input sequence\n",
        "    idx_token = torch.tensor(data_input_idx) # change list to tensor\n",
        "\n",
        "    return idx_token\n",
        "\n",
        "# Part 3: idx_z, the last token ID for each sequence\n",
        "def get_idx_z(data):\n",
        "      idx_z = []\n",
        "\n",
        "      for i in range(len(data)):\n",
        "          idx_zi = data[i][0][-1]\n",
        "          idx_z.append(idx_zi)\n",
        "\n",
        "      idx_z = torch.tensor(idx_z)\n",
        "      return idx_z\n",
        "\n",
        "# Part 4: C/C_alpha, the next token ID for each sequence\n",
        "def get_C_alpha(data):\n",
        "    C = []\n",
        "    for i in range(len(data)):\n",
        "      C_i = data[i][-1]\n",
        "      C.append(C_i)\n",
        "\n",
        "    C_alpha = torch.tensor(C)\n",
        "\n",
        "    return C_alpha\n",
        "\n",
        "# Part 5: get scc_klst: scc for each TPG\n",
        "def get_scc_klst (idx_token, C_alpha):\n",
        "    scc_klst = []\n",
        "\n",
        "    for k in range(K):\n",
        "        tarjan_solver = Tarjan(K)\n",
        "        mask = idx_token[:, -1] == k\n",
        "        cnt = torch.sum(mask).item()\n",
        "        if cnt == 0:\n",
        "            scc_klst.append([])\n",
        "            continue\n",
        "\n",
        "        tarjan_solver.initialize(idx_token[mask], C_alpha[mask])\n",
        "        tarjan_solver.run()\n",
        "        #tarjan_solver.output()\n",
        "        scc_lst = tarjan_solver.get_scc()\n",
        "        scc_klst.append(scc_lst)\n",
        "\n",
        "    return scc_klst\n",
        "\n",
        "# Part 6: z, the last token of each sequence\n",
        "def get_z(data, dict_token, toy_case, batch_toy):\n",
        "\n",
        "    X = get_X(data, dict_token)\n",
        "    if toy_case and batch_toy:\n",
        "        input_z = []\n",
        "        for i in range(len(X)):\n",
        "            zi = X[i][-1]\n",
        "            input_z.append(zi)\n",
        "        input_z = torch.stack(input_z)\n",
        "        assert input_z.shape == (n, d)\n",
        "    else:\n",
        "        input_z = X[:, -1].unsqueeze(1) # [n, d]\n",
        "\n",
        "    z = input_z.double() #dtype: torch.float64\n",
        "    return z\n",
        "\n",
        "# Part 7: get adj_mat (one of the input parameters of W_svm_solver_cvxpy)\n",
        "def get_adjacency_matrix(token_choice, idx_token, C_alpha):\n",
        "    if token_choice == 'equi-corr':\n",
        "            adj_mat = np.zeros((K -1, K - 1, K -1)) # #of distinct last tokens, |ID|, |ID|\n",
        "    else:\n",
        "        adj_mat = np.zeros((K , K , K )) # #of distinct last tokens, |ID|, |ID|\n",
        "\n",
        "    for i in range(len(idx_token)):\n",
        "        for j in range(len(idx_token[i])):\n",
        "            if C_alpha[i] == idx_token[i][j]:\n",
        "                continue\n",
        "            adj_mat[idx_token[i][-1], C_alpha[i], idx_token[i][j]] = 1\n",
        "\n",
        "    return adj_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU3PYgFjxmdn"
      },
      "source": [
        "#### 11.3 Calculate $W^{svm}_1$, $W^{svm}_2$, and $W^{svm}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COZjjmZb0_90"
      },
      "outputs": [],
      "source": [
        "def get_input_paras(data, dict_token):\n",
        "\n",
        "      X = get_X(data, dict_token)\n",
        "      idx_token = get_idx_token (data)\n",
        "      z = get_z(data, dict_token, toy_case, batch_toy)\n",
        "      idx_z = get_idx_z(data)\n",
        "      C_alpha = get_C_alpha(data)\n",
        "      scc_klst = get_scc_klst(idx_token, C_alpha)\n",
        "      adj_mat = get_adjacency_matrix (token_choice = token_choice, idx_token = idx_token, C_alpha = C_alpha)\n",
        "\n",
        "\n",
        "      return X, idx_token, z, idx_z, C_alpha, scc_klst, adj_mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkU_QndyAgxL"
      },
      "source": [
        "### Step 12. Generate $W_1(\\tau)$, $W_2(\\tau)$, $W(\\tau)$, where $\\tau = 1, ...., ITN$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kdparDwY08Q"
      },
      "source": [
        "#### Step 12.1: self-attention model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZG2Fo7i3o5D"
      },
      "outputs": [],
      "source": [
        "model = MLayerAttn(d, regress = True, n_layer = nlayer, dim_t = T,\n",
        "                        identity_W=False, identity_V = True,\n",
        "                        factorize_W = factorize_w, init = initialize_w,\n",
        "                        skip = skip, layer_norm = layer_norm, avg_norm = avg_norm,\n",
        "                ).double()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJBSc5pPqSQx"
      },
      "source": [
        "#### Step 12.2: $W$ training - train_W()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWw0Zi_klIs7"
      },
      "outputs": [],
      "source": [
        "# Required input parameters for training\n",
        "def get_para_list (factorize_w, layer_norm, avg_norm):\n",
        "\n",
        "      if factorize_w:\n",
        "            parameter_list = [model.query1.weight, model.query2.weight, model.key1.weight, model.key2.weight]\n",
        "      else:\n",
        "          parameter_list = [m.weight for m in model.qklist]\n",
        "\n",
        "      if layer_norm and not avg_norm:\n",
        "          parameter_list += [model.ln.weight, model.ln.bias]\n",
        "\n",
        "      return parameter_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A15UCMcGCt14"
      },
      "source": [
        "### Step 13. Correlation coefficient between $W^{svm}$ and $W(\\tau)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhF6Ng62X8DO"
      },
      "source": [
        "- Get correlation coefficient\n",
        "- Visualize Correlation Coefficient and Iteration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q2-K-H3WLAq"
      },
      "source": [
        "# Part 4: Save Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWiEkh9BWRuW"
      },
      "outputs": [],
      "source": [
        "def before_save_results(df_results):\n",
        "\n",
        "    col_dict_tensor = ['dictionary', 'test_X_12cb', 'test_z_12cb']\n",
        "    col_dict_array = ['W_svm_12cb', 'W_tau_12cb', 'last_W_12cb']\n",
        "    col_list = ['correlation_1', 'correlation_2', 'correlation_cb']\n",
        "    col_dict = ['empir_TPG_12cb', 'training_data', 'SCC_12cb', 'testing_data', 'testing_data_new', 'test_SCC_12cb']\n",
        "    col_tensor = ['pseudo_Vocab']\n",
        "\n",
        "    df_results_save = df_results.copy()\n",
        "    for col in df_results_save.columns:\n",
        "\n",
        "        if col in col_dict_tensor or col in col_dict_array:\n",
        "            for i in df_results.index:\n",
        "                for key, value in df_results_save[col][i].items():\n",
        "                    if type(value) != list:\n",
        "                        df_results_save[col][i][key] = value.tolist()\n",
        "\n",
        "        elif col in col_tensor:\n",
        "            for i in df_results.index:\n",
        "                if type(df_results_save.loc[i, col]) != list:\n",
        "                    df_results_save.at[i, col] = df_results_save.at[i, col].tolist()\n",
        "\n",
        "        else:\n",
        "            df_results_save[col] = df_results_save[col]\n",
        "\n",
        "    return df_results_save\n",
        "\n",
        "def after_open_results(df_results_open):\n",
        "\n",
        "    col_dict_tensor = ['dictionary', 'test_X_12cb', 'test_z_12cb']\n",
        "    col_dict_array = ['W_svm_12cb', 'W_tau_12cb', 'last_W_12cb']\n",
        "    col_list = ['correlation_1', 'correlation_2', 'correlation_cb']\n",
        "    col_dict = ['empir_TPG_12cb', 'training_data', 'SCC_12cb', 'testing_data', 'testing_data_new', 'test_SCC_12cb']\n",
        "    col_dict_str = ['dictionary']\n",
        "    col_tensor = ['pseudo_Vocab']\n",
        "    for col in df_results_open.columns:\n",
        "\n",
        "        if df_results_open[col].dtype == 'object' and col != 'token_choice':\n",
        "\n",
        "            for i in df_results_open.index:\n",
        "\n",
        "                if col in col_dict_tensor:\n",
        "                    for key, value in df_results_open[col][i].items():\n",
        "                        if type(value) != torch.tensor:\n",
        "                            df_results_open[col][i][key] = torch.tensor(df_results_open[col][i][key], dtype=torch.float64)\n",
        "                if col in col_dict_str:\n",
        "                    df_results_open.at[i, col] = {int(key): value for key, value in df_results_open.at[i, col].items()}\n",
        "\n",
        "                if col in col_dict_array:\n",
        "                    for key, value in df_results_open[col][i].items():\n",
        "                        if type(value) != np.ndarray:\n",
        "                            df_results_open[col][i][key] = np.array(df_results_open[col][i][key])\n",
        "\n",
        "                if col in col_tensor:\n",
        "                    if type(df_results_open.loc[i, col]) != torch.tensor:\n",
        "                        df_results_open.at[i, col] = torch.tensor(df_results_open.at[i, col], dtype=torch.float64)\n",
        "        else:\n",
        "            df_results_open[col] = df_results_open[col]\n",
        "\n",
        "    return df_results_open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv_lZJq2UBto"
      },
      "source": [
        "# \"Training Only\": Integration of Part 1 - Part 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38aXrpNY4pqV"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLKXese3F5Ry"
      },
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "\n",
        "K = 10 # Vocabulary size\n",
        "L = 4 # Number of arrows to randomly choose\n",
        "d = 16 # dim of embedding token\n",
        "T = 4 # the length of sequence (not include the next token)\n",
        "test_T = 8 # generate the another group of test data for having repeated tokens in case 4\n",
        "token_choice = 'random'\n",
        "ITN = 8000\n",
        "lr = 0.01\n",
        "part = 2 # each part with 25 epochs, then combine 2 parts with the same parameter settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCQKJ7BZPH-k"
      },
      "outputs": [],
      "source": [
        "inspect = False\n",
        "use_double = True\n",
        "batch = True\n",
        "loss_type = 'nll'\n",
        "separa = False\n",
        "use_scc = True\n",
        "rep_seq = False\n",
        "check_label = True\n",
        "cls_choice = 'iden'\n",
        "check_asyc = False\n",
        "same_last_token = False\n",
        "toy_case = False\n",
        "batch_toy = False\n",
        "custom_initialize = False\n",
        "nlayer = 1\n",
        "skip = False\n",
        "layer_norm = False\n",
        "avg_norm = False\n",
        "factorize_w = False\n",
        "initialize_w = 'default'\n",
        "strong_default = False\n",
        "initialize_wfin = 'zero'\n",
        "reg_wfin = 0\n",
        "norm_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fZaezqfFL0cd",
        "outputId": "1298a50c-859f-4d11-918b-f809adbf51e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "********************************************\n",
            "Current epoch: 0\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9910\n",
            "Current iteration: 500, Loss: 0.6037\n",
            "Current iteration: 1000, Loss: 0.4576\n",
            "Current iteration: 1500, Loss: 0.3735\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3201\n",
            "Current iteration: 2500, Loss: 0.2842\n",
            "Current iteration: 3000, Loss: 0.2592\n",
            "Current iteration: 3500, Loss: 0.2416\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2289\n",
            "Current iteration: 4500, Loss: 0.2198\n",
            "Current iteration: 5000, Loss: 0.2133\n",
            "Current iteration: 5500, Loss: 0.2085\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2050\n",
            "Current iteration: 6500, Loss: 0.2025\n",
            "Current iteration: 7000, Loss: 0.2007\n",
            "Current iteration: 7500, Loss: 0.1994\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9765884759760999\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (31, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9679\n",
            "Current iteration: 500, Loss: 0.5540\n",
            "Current iteration: 1000, Loss: 0.4209\n",
            "Current iteration: 1500, Loss: 0.3433\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2881\n",
            "Current iteration: 2500, Loss: 0.2464\n",
            "Current iteration: 3000, Loss: 0.2144\n",
            "Current iteration: 3500, Loss: 0.1896\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1705\n",
            "Current iteration: 4500, Loss: 0.1559\n",
            "Current iteration: 5000, Loss: 0.1448\n",
            "Current iteration: 5500, Loss: 0.1364\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1300\n",
            "Current iteration: 6500, Loss: 0.1252\n",
            "Current iteration: 7000, Loss: 0.1216\n",
            "Current iteration: 7500, Loss: 0.1189\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9720329306347407\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (30, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (51, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (31, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (44, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9867\n",
            "Current iteration: 500, Loss: 0.6191\n",
            "Current iteration: 1000, Loss: 0.5140\n",
            "Current iteration: 1500, Loss: 0.4588\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4229\n",
            "Current iteration: 2500, Loss: 0.3970\n",
            "Current iteration: 3000, Loss: 0.3772\n",
            "Current iteration: 3500, Loss: 0.3618\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3498\n",
            "Current iteration: 4500, Loss: 0.3405\n",
            "Current iteration: 5000, Loss: 0.3332\n",
            "Current iteration: 5500, Loss: 0.3276\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3232\n",
            "Current iteration: 6500, Loss: 0.3198\n",
            "Current iteration: 7000, Loss: 0.3172\n",
            "Current iteration: 7500, Loss: 0.3151\n",
            "For data_combine correlation of W and Wsvm:  0.949276453058546\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 1\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9694\n",
            "Current iteration: 500, Loss: 0.6083\n",
            "Current iteration: 1000, Loss: 0.4696\n",
            "Current iteration: 1500, Loss: 0.3939\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3457\n",
            "Current iteration: 2500, Loss: 0.3141\n",
            "Current iteration: 3000, Loss: 0.2934\n",
            "Current iteration: 3500, Loss: 0.2798\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2707\n",
            "Current iteration: 4500, Loss: 0.2647\n",
            "Current iteration: 5000, Loss: 0.2607\n",
            "Current iteration: 5500, Loss: 0.2581\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2563\n",
            "Current iteration: 6500, Loss: 0.2551\n",
            "Current iteration: 7000, Loss: 0.2543\n",
            "Current iteration: 7500, Loss: 0.2538\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9779455849406764\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9838\n",
            "Current iteration: 500, Loss: 0.5479\n",
            "Current iteration: 1000, Loss: 0.3827\n",
            "Current iteration: 1500, Loss: 0.2926\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2378\n",
            "Current iteration: 2500, Loss: 0.2021\n",
            "Current iteration: 3000, Loss: 0.1785\n",
            "Current iteration: 3500, Loss: 0.1628\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1523\n",
            "Current iteration: 4500, Loss: 0.1453\n",
            "Current iteration: 5000, Loss: 0.1407\n",
            "Current iteration: 5500, Loss: 0.1377\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1356\n",
            "Current iteration: 6500, Loss: 0.1343\n",
            "Current iteration: 7000, Loss: 0.1333\n",
            "Current iteration: 7500, Loss: 0.1327\n",
            "For data_topic_2 correlation of W and Wsvm:  0.982058192624893\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (18, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (19, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (33, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (36, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (50, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (50, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (32, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (1, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (1, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (45, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (46, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9818\n",
            "Current iteration: 500, Loss: 0.6618\n",
            "Current iteration: 1000, Loss: 0.5547\n",
            "Current iteration: 1500, Loss: 0.4971\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4620\n",
            "Current iteration: 2500, Loss: 0.4392\n",
            "Current iteration: 3000, Loss: 0.4239\n",
            "Current iteration: 3500, Loss: 0.4133\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.4057\n",
            "Current iteration: 4500, Loss: 0.4003\n",
            "Current iteration: 5000, Loss: 0.3964\n",
            "Current iteration: 5500, Loss: 0.3936\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3915\n",
            "Current iteration: 6500, Loss: 0.3900\n",
            "Current iteration: 7000, Loss: 0.3889\n",
            "Current iteration: 7500, Loss: 0.3881\n",
            "For data_combine correlation of W and Wsvm:  0.9507170390191012\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 2\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (20, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (4, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9172\n",
            "Current iteration: 500, Loss: 0.5285\n",
            "Current iteration: 1000, Loss: 0.3934\n",
            "Current iteration: 1500, Loss: 0.3235\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2844\n",
            "Current iteration: 2500, Loss: 0.2613\n",
            "Current iteration: 3000, Loss: 0.2473\n",
            "Current iteration: 3500, Loss: 0.2388\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2335\n",
            "Current iteration: 4500, Loss: 0.2303\n",
            "Current iteration: 5000, Loss: 0.2283\n",
            "Current iteration: 5500, Loss: 0.2271\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2264\n",
            "Current iteration: 6500, Loss: 0.2260\n",
            "Current iteration: 7000, Loss: 0.2258\n",
            "Current iteration: 7500, Loss: 0.2257\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9742241666238106\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9236\n",
            "Current iteration: 500, Loss: 0.5182\n",
            "Current iteration: 1000, Loss: 0.3642\n",
            "Current iteration: 1500, Loss: 0.2762\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2185\n",
            "Current iteration: 2500, Loss: 0.1796\n",
            "Current iteration: 3000, Loss: 0.1530\n",
            "Current iteration: 3500, Loss: 0.1348\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1225\n",
            "Current iteration: 4500, Loss: 0.1141\n",
            "Current iteration: 5000, Loss: 0.1085\n",
            "Current iteration: 5500, Loss: 0.1047\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1021\n",
            "Current iteration: 6500, Loss: 0.1004\n",
            "Current iteration: 7000, Loss: 0.0993\n",
            "Current iteration: 7500, Loss: 0.0985\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9891245344344546\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (33, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (43, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (42, 1))), Inequality(Expression(AFFINE, UNKNOWN, (50, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.8831\n",
            "Current iteration: 500, Loss: 0.5786\n",
            "Current iteration: 1000, Loss: 0.4871\n",
            "Current iteration: 1500, Loss: 0.4346\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4001\n",
            "Current iteration: 2500, Loss: 0.3759\n",
            "Current iteration: 3000, Loss: 0.3582\n",
            "Current iteration: 3500, Loss: 0.3448\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3345\n",
            "Current iteration: 4500, Loss: 0.3267\n",
            "Current iteration: 5000, Loss: 0.3206\n",
            "Current iteration: 5500, Loss: 0.3158\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3121\n",
            "Current iteration: 6500, Loss: 0.3092\n",
            "Current iteration: 7000, Loss: 0.3069\n",
            "Current iteration: 7500, Loss: 0.3052\n",
            "For data_combine correlation of W and Wsvm:  0.9701846222764872\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 3\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0480\n",
            "Current iteration: 500, Loss: 0.5636\n",
            "Current iteration: 1000, Loss: 0.4141\n",
            "Current iteration: 1500, Loss: 0.3284\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2728\n",
            "Current iteration: 2500, Loss: 0.2349\n",
            "Current iteration: 3000, Loss: 0.2082\n",
            "Current iteration: 3500, Loss: 0.1892\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1754\n",
            "Current iteration: 4500, Loss: 0.1655\n",
            "Current iteration: 5000, Loss: 0.1582\n",
            "Current iteration: 5500, Loss: 0.1530\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1493\n",
            "Current iteration: 6500, Loss: 0.1466\n",
            "Current iteration: 7000, Loss: 0.1447\n",
            "Current iteration: 7500, Loss: 0.1434\n",
            "For data_topic_1 correlation of W and Wsvm:  0.966708765497769\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (31, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9910\n",
            "Current iteration: 500, Loss: 0.5881\n",
            "Current iteration: 1000, Loss: 0.4855\n",
            "Current iteration: 1500, Loss: 0.4241\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3773\n",
            "Current iteration: 2500, Loss: 0.3402\n",
            "Current iteration: 3000, Loss: 0.3105\n",
            "Current iteration: 3500, Loss: 0.2868\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2679\n",
            "Current iteration: 4500, Loss: 0.2528\n",
            "Current iteration: 5000, Loss: 0.2407\n",
            "Current iteration: 5500, Loss: 0.2311\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2235\n",
            "Current iteration: 6500, Loss: 0.2174\n",
            "Current iteration: 7000, Loss: 0.2126\n",
            "Current iteration: 7500, Loss: 0.2087\n",
            "For data_topic_2 correlation of W and Wsvm:  0.970265136707287\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (41, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (45, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (66, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (35, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (49, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (31, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (39, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (34, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (1, 1))), Inequality(Expression(AFFINE, UNKNOWN, (37, 1))), Inequality(Expression(AFFINE, UNKNOWN, (47, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9649\n",
            "Current iteration: 500, Loss: 0.6453\n",
            "Current iteration: 1000, Loss: 0.5866\n",
            "Current iteration: 1500, Loss: 0.5543\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.5325\n",
            "Current iteration: 2500, Loss: 0.5165\n",
            "Current iteration: 3000, Loss: 0.5044\n",
            "Current iteration: 3500, Loss: 0.4951\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.4879\n",
            "Current iteration: 4500, Loss: 0.4823\n",
            "Current iteration: 5000, Loss: 0.4780\n",
            "Current iteration: 5500, Loss: 0.4745\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.4716\n",
            "Current iteration: 6500, Loss: 0.4692\n",
            "Current iteration: 7000, Loss: 0.4672\n",
            "Current iteration: 7500, Loss: 0.4656\n",
            "For data_combine correlation of W and Wsvm:  0.9000467856440901\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 4\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9531\n",
            "Current iteration: 500, Loss: 0.5057\n",
            "Current iteration: 1000, Loss: 0.3292\n",
            "Current iteration: 1500, Loss: 0.2317\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.1721\n",
            "Current iteration: 2500, Loss: 0.1336\n",
            "Current iteration: 3000, Loss: 0.1079\n",
            "Current iteration: 3500, Loss: 0.0906\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.0788\n",
            "Current iteration: 4500, Loss: 0.0708\n",
            "Current iteration: 5000, Loss: 0.0653\n",
            "Current iteration: 5500, Loss: 0.0616\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.0590\n",
            "Current iteration: 6500, Loss: 0.0573\n",
            "Current iteration: 7000, Loss: 0.0561\n",
            "Current iteration: 7500, Loss: 0.0553\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9785793099017142\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (30, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0259\n",
            "Current iteration: 500, Loss: 0.5867\n",
            "Current iteration: 1000, Loss: 0.4240\n",
            "Current iteration: 1500, Loss: 0.3329\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2754\n",
            "Current iteration: 2500, Loss: 0.2365\n",
            "Current iteration: 3000, Loss: 0.2098\n",
            "Current iteration: 3500, Loss: 0.1914\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1788\n",
            "Current iteration: 4500, Loss: 0.1702\n",
            "Current iteration: 5000, Loss: 0.1644\n",
            "Current iteration: 5500, Loss: 0.1606\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1580\n",
            "Current iteration: 6500, Loss: 0.1562\n",
            "Current iteration: 7000, Loss: 0.1551\n",
            "Current iteration: 7500, Loss: 0.1543\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9851763380210502\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (67, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (27, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (53, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (45, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (45, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0017\n",
            "Current iteration: 500, Loss: 0.6119\n",
            "Current iteration: 1000, Loss: 0.4857\n",
            "Current iteration: 1500, Loss: 0.4168\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3713\n",
            "Current iteration: 2500, Loss: 0.3385\n",
            "Current iteration: 3000, Loss: 0.3140\n",
            "Current iteration: 3500, Loss: 0.2953\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2809\n",
            "Current iteration: 4500, Loss: 0.2698\n",
            "Current iteration: 5000, Loss: 0.2610\n",
            "Current iteration: 5500, Loss: 0.2541\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2487\n",
            "Current iteration: 6500, Loss: 0.2445\n",
            "Current iteration: 7000, Loss: 0.2411\n",
            "Current iteration: 7500, Loss: 0.2384\n",
            "For data_combine correlation of W and Wsvm:  0.970473570058306\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 5\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9027\n",
            "Current iteration: 500, Loss: 0.5642\n",
            "Current iteration: 1000, Loss: 0.4504\n",
            "Current iteration: 1500, Loss: 0.3866\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3454\n",
            "Current iteration: 2500, Loss: 0.3178\n",
            "Current iteration: 3000, Loss: 0.2989\n",
            "Current iteration: 3500, Loss: 0.2857\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2765\n",
            "Current iteration: 4500, Loss: 0.2702\n",
            "Current iteration: 5000, Loss: 0.2658\n",
            "Current iteration: 5500, Loss: 0.2628\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2608\n",
            "Current iteration: 6500, Loss: 0.2594\n",
            "Current iteration: 7000, Loss: 0.2585\n",
            "Current iteration: 7500, Loss: 0.2580\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9797566861464533\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (19, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9557\n",
            "Current iteration: 500, Loss: 0.6334\n",
            "Current iteration: 1000, Loss: 0.5193\n",
            "Current iteration: 1500, Loss: 0.4400\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3799\n",
            "Current iteration: 2500, Loss: 0.3341\n",
            "Current iteration: 3000, Loss: 0.2990\n",
            "Current iteration: 3500, Loss: 0.2722\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2518\n",
            "Current iteration: 4500, Loss: 0.2364\n",
            "Current iteration: 5000, Loss: 0.2247\n",
            "Current iteration: 5500, Loss: 0.2158\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2091\n",
            "Current iteration: 6500, Loss: 0.2041\n",
            "Current iteration: 7000, Loss: 0.2002\n",
            "Current iteration: 7500, Loss: 0.1973\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9612540587252113\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (51, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (34, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (32, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (20, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (42, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (54, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9510\n",
            "Current iteration: 500, Loss: 0.6500\n",
            "Current iteration: 1000, Loss: 0.5616\n",
            "Current iteration: 1500, Loss: 0.5096\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4728\n",
            "Current iteration: 2500, Loss: 0.4453\n",
            "Current iteration: 3000, Loss: 0.4243\n",
            "Current iteration: 3500, Loss: 0.4080\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3954\n",
            "Current iteration: 4500, Loss: 0.3856\n",
            "Current iteration: 5000, Loss: 0.3778\n",
            "Current iteration: 5500, Loss: 0.3717\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3669\n",
            "Current iteration: 6500, Loss: 0.3631\n",
            "Current iteration: 7000, Loss: 0.3600\n",
            "Current iteration: 7500, Loss: 0.3576\n",
            "For data_combine correlation of W and Wsvm:  0.9272487908583162\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 6\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0055\n",
            "Current iteration: 500, Loss: 0.5767\n",
            "Current iteration: 1000, Loss: 0.4118\n",
            "Current iteration: 1500, Loss: 0.3237\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2686\n",
            "Current iteration: 2500, Loss: 0.2315\n",
            "Current iteration: 3000, Loss: 0.2060\n",
            "Current iteration: 3500, Loss: 0.1884\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1762\n",
            "Current iteration: 4500, Loss: 0.1678\n",
            "Current iteration: 5000, Loss: 0.1621\n",
            "Current iteration: 5500, Loss: 0.1582\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1556\n",
            "Current iteration: 6500, Loss: 0.1538\n",
            "Current iteration: 7000, Loss: 0.1526\n",
            "Current iteration: 7500, Loss: 0.1518\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9790187646487902\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (4, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9722\n",
            "Current iteration: 500, Loss: 0.5901\n",
            "Current iteration: 1000, Loss: 0.4536\n",
            "Current iteration: 1500, Loss: 0.3796\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3305\n",
            "Current iteration: 2500, Loss: 0.2949\n",
            "Current iteration: 3000, Loss: 0.2682\n",
            "Current iteration: 3500, Loss: 0.2479\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2324\n",
            "Current iteration: 4500, Loss: 0.2205\n",
            "Current iteration: 5000, Loss: 0.2112\n",
            "Current iteration: 5500, Loss: 0.2039\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1983\n",
            "Current iteration: 6500, Loss: 0.1939\n",
            "Current iteration: 7000, Loss: 0.1904\n",
            "Current iteration: 7500, Loss: 0.1878\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9745126456227309\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (46, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (47, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (38, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (40, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (33, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (57, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (26, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9588\n",
            "Current iteration: 500, Loss: 0.6396\n",
            "Current iteration: 1000, Loss: 0.5594\n",
            "Current iteration: 1500, Loss: 0.5210\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4969\n",
            "Current iteration: 2500, Loss: 0.4803\n",
            "Current iteration: 3000, Loss: 0.4686\n",
            "Current iteration: 3500, Loss: 0.4603\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.4545\n",
            "Current iteration: 4500, Loss: 0.4507\n",
            "Current iteration: 5000, Loss: 0.4483\n",
            "Current iteration: 5500, Loss: 0.4467\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.4457\n",
            "Current iteration: 6500, Loss: 0.4451\n",
            "Current iteration: 7000, Loss: 0.4448\n",
            "Current iteration: 7500, Loss: 0.4447\n",
            "For data_combine correlation of W and Wsvm:  0.9032198637914516\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 7\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (20, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9582\n",
            "Current iteration: 500, Loss: 0.6128\n",
            "Current iteration: 1000, Loss: 0.4809\n",
            "Current iteration: 1500, Loss: 0.3927\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3291\n",
            "Current iteration: 2500, Loss: 0.2821\n",
            "Current iteration: 3000, Loss: 0.2468\n",
            "Current iteration: 3500, Loss: 0.2200\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1997\n",
            "Current iteration: 4500, Loss: 0.1843\n",
            "Current iteration: 5000, Loss: 0.1726\n",
            "Current iteration: 5500, Loss: 0.1636\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1569\n",
            "Current iteration: 6500, Loss: 0.1518\n",
            "Current iteration: 7000, Loss: 0.1479\n",
            "Current iteration: 7500, Loss: 0.1450\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9829348539903864\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9937\n",
            "Current iteration: 500, Loss: 0.5574\n",
            "Current iteration: 1000, Loss: 0.4209\n",
            "Current iteration: 1500, Loss: 0.3423\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2901\n",
            "Current iteration: 2500, Loss: 0.2533\n",
            "Current iteration: 3000, Loss: 0.2263\n",
            "Current iteration: 3500, Loss: 0.2059\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1903\n",
            "Current iteration: 4500, Loss: 0.1784\n",
            "Current iteration: 5000, Loss: 0.1694\n",
            "Current iteration: 5500, Loss: 0.1627\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1576\n",
            "Current iteration: 6500, Loss: 0.1539\n",
            "Current iteration: 7000, Loss: 0.1511\n",
            "Current iteration: 7500, Loss: 0.1490\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9792487392429939\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (23, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (56, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (27, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (47, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (1, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0172\n",
            "Current iteration: 500, Loss: 0.6450\n",
            "Current iteration: 1000, Loss: 0.5508\n",
            "Current iteration: 1500, Loss: 0.4959\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4576\n",
            "Current iteration: 2500, Loss: 0.4286\n",
            "Current iteration: 3000, Loss: 0.4059\n",
            "Current iteration: 3500, Loss: 0.3879\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3733\n",
            "Current iteration: 4500, Loss: 0.3614\n",
            "Current iteration: 5000, Loss: 0.3515\n",
            "Current iteration: 5500, Loss: 0.3431\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3360\n",
            "Current iteration: 6500, Loss: 0.3298\n",
            "Current iteration: 7000, Loss: 0.3245\n",
            "Current iteration: 7500, Loss: 0.3200\n",
            "For data_combine correlation of W and Wsvm:  0.9130083608268502\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 8\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0046\n",
            "Current iteration: 500, Loss: 0.5398\n",
            "Current iteration: 1000, Loss: 0.3885\n",
            "Current iteration: 1500, Loss: 0.3003\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2408\n",
            "Current iteration: 2500, Loss: 0.1983\n",
            "Current iteration: 3000, Loss: 0.1673\n",
            "Current iteration: 3500, Loss: 0.1445\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1275\n",
            "Current iteration: 4500, Loss: 0.1150\n",
            "Current iteration: 5000, Loss: 0.1056\n",
            "Current iteration: 5500, Loss: 0.0986\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.0934\n",
            "Current iteration: 6500, Loss: 0.0895\n",
            "Current iteration: 7000, Loss: 0.0867\n",
            "Current iteration: 7500, Loss: 0.0845\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9743761605898036\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (34, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0057\n",
            "Current iteration: 500, Loss: 0.5899\n",
            "Current iteration: 1000, Loss: 0.4555\n",
            "Current iteration: 1500, Loss: 0.3814\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3298\n",
            "Current iteration: 2500, Loss: 0.2915\n",
            "Current iteration: 3000, Loss: 0.2624\n",
            "Current iteration: 3500, Loss: 0.2402\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2231\n",
            "Current iteration: 4500, Loss: 0.2100\n",
            "Current iteration: 5000, Loss: 0.1999\n",
            "Current iteration: 5500, Loss: 0.1922\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1863\n",
            "Current iteration: 6500, Loss: 0.1818\n",
            "Current iteration: 7000, Loss: 0.1783\n",
            "Current iteration: 7500, Loss: 0.1757\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9764356652990887\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (51, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (40, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (46, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (59, 1))), Inequality(Expression(AFFINE, UNKNOWN, (4, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (47, 1))), Inequality(Expression(AFFINE, UNKNOWN, (47, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0155\n",
            "Current iteration: 500, Loss: 0.6185\n",
            "Current iteration: 1000, Loss: 0.5156\n",
            "Current iteration: 1500, Loss: 0.4583\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4191\n",
            "Current iteration: 2500, Loss: 0.3898\n",
            "Current iteration: 3000, Loss: 0.3671\n",
            "Current iteration: 3500, Loss: 0.3491\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3345\n",
            "Current iteration: 4500, Loss: 0.3226\n",
            "Current iteration: 5000, Loss: 0.3129\n",
            "Current iteration: 5500, Loss: 0.3050\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2986\n",
            "Current iteration: 6500, Loss: 0.2933\n",
            "Current iteration: 7000, Loss: 0.2890\n",
            "Current iteration: 7500, Loss: 0.2854\n",
            "For data_combine correlation of W and Wsvm:  0.9548639008828484\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 9\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (45, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9530\n",
            "Current iteration: 500, Loss: 0.4845\n",
            "Current iteration: 1000, Loss: 0.3202\n",
            "Current iteration: 1500, Loss: 0.2387\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.1938\n",
            "Current iteration: 2500, Loss: 0.1683\n",
            "Current iteration: 3000, Loss: 0.1535\n",
            "Current iteration: 3500, Loss: 0.1448\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1395\n",
            "Current iteration: 4500, Loss: 0.1363\n",
            "Current iteration: 5000, Loss: 0.1344\n",
            "Current iteration: 5500, Loss: 0.1332\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1325\n",
            "Current iteration: 6500, Loss: 0.1322\n",
            "Current iteration: 7000, Loss: 0.1320\n",
            "Current iteration: 7500, Loss: 0.1318\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9706343931555224\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (31, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9472\n",
            "Current iteration: 500, Loss: 0.5742\n",
            "Current iteration: 1000, Loss: 0.4345\n",
            "Current iteration: 1500, Loss: 0.3525\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3018\n",
            "Current iteration: 2500, Loss: 0.2701\n",
            "Current iteration: 3000, Loss: 0.2498\n",
            "Current iteration: 3500, Loss: 0.2365\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2278\n",
            "Current iteration: 4500, Loss: 0.2220\n",
            "Current iteration: 5000, Loss: 0.2183\n",
            "Current iteration: 5500, Loss: 0.2158\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2142\n",
            "Current iteration: 6500, Loss: 0.2132\n",
            "Current iteration: 7000, Loss: 0.2125\n",
            "Current iteration: 7500, Loss: 0.2122\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9754223034273177\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (27, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (77, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (50, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9472\n",
            "Current iteration: 500, Loss: 0.5784\n",
            "Current iteration: 1000, Loss: 0.4638\n",
            "Current iteration: 1500, Loss: 0.4032\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3670\n",
            "Current iteration: 2500, Loss: 0.3435\n",
            "Current iteration: 3000, Loss: 0.3274\n",
            "Current iteration: 3500, Loss: 0.3162\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3083\n",
            "Current iteration: 4500, Loss: 0.3027\n",
            "Current iteration: 5000, Loss: 0.2988\n",
            "Current iteration: 5500, Loss: 0.2960\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2941\n",
            "Current iteration: 6500, Loss: 0.2927\n",
            "Current iteration: 7000, Loss: 0.2918\n",
            "Current iteration: 7500, Loss: 0.2911\n",
            "For data_combine correlation of W and Wsvm:  0.9612028213269278\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 10\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (46, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9784\n",
            "Current iteration: 500, Loss: 0.5132\n",
            "Current iteration: 1000, Loss: 0.3416\n",
            "Current iteration: 1500, Loss: 0.2495\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.1910\n",
            "Current iteration: 2500, Loss: 0.1514\n",
            "Current iteration: 3000, Loss: 0.1242\n",
            "Current iteration: 3500, Loss: 0.1057\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.0931\n",
            "Current iteration: 4500, Loss: 0.0845\n",
            "Current iteration: 5000, Loss: 0.0788\n",
            "Current iteration: 5500, Loss: 0.0749\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.0723\n",
            "Current iteration: 6500, Loss: 0.0705\n",
            "Current iteration: 7000, Loss: 0.0694\n",
            "Current iteration: 7500, Loss: 0.0686\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9855240366774347\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9241\n",
            "Current iteration: 500, Loss: 0.5422\n",
            "Current iteration: 1000, Loss: 0.3946\n",
            "Current iteration: 1500, Loss: 0.3106\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2585\n",
            "Current iteration: 2500, Loss: 0.2251\n",
            "Current iteration: 3000, Loss: 0.2034\n",
            "Current iteration: 3500, Loss: 0.1895\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1806\n",
            "Current iteration: 4500, Loss: 0.1750\n",
            "Current iteration: 5000, Loss: 0.1714\n",
            "Current iteration: 5500, Loss: 0.1691\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1677\n",
            "Current iteration: 6500, Loss: 0.1668\n",
            "Current iteration: 7000, Loss: 0.1662\n",
            "Current iteration: 7500, Loss: 0.1659\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9835930335826035\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (28, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (49, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (34, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (23, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (64, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1))), Inequality(Expression(AFFINE, UNKNOWN, (43, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0084\n",
            "Current iteration: 500, Loss: 0.6040\n",
            "Current iteration: 1000, Loss: 0.5006\n",
            "Current iteration: 1500, Loss: 0.4508\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4197\n",
            "Current iteration: 2500, Loss: 0.3991\n",
            "Current iteration: 3000, Loss: 0.3851\n",
            "Current iteration: 3500, Loss: 0.3756\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3690\n",
            "Current iteration: 4500, Loss: 0.3644\n",
            "Current iteration: 5000, Loss: 0.3610\n",
            "Current iteration: 5500, Loss: 0.3587\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3570\n",
            "Current iteration: 6500, Loss: 0.3557\n",
            "Current iteration: 7000, Loss: 0.3549\n",
            "Current iteration: 7500, Loss: 0.3542\n",
            "For data_combine correlation of W and Wsvm:  0.9715193375468439\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 11\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (34, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9538\n",
            "Current iteration: 500, Loss: 0.6014\n",
            "Current iteration: 1000, Loss: 0.4678\n",
            "Current iteration: 1500, Loss: 0.3822\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3225\n",
            "Current iteration: 2500, Loss: 0.2801\n",
            "Current iteration: 3000, Loss: 0.2496\n",
            "Current iteration: 3500, Loss: 0.2279\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2126\n",
            "Current iteration: 4500, Loss: 0.2018\n",
            "Current iteration: 5000, Loss: 0.1943\n",
            "Current iteration: 5500, Loss: 0.1890\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1853\n",
            "Current iteration: 6500, Loss: 0.1827\n",
            "Current iteration: 7000, Loss: 0.1809\n",
            "Current iteration: 7500, Loss: 0.1797\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9714576873295763\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9342\n",
            "Current iteration: 500, Loss: 0.5872\n",
            "Current iteration: 1000, Loss: 0.4635\n",
            "Current iteration: 1500, Loss: 0.3894\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3364\n",
            "Current iteration: 2500, Loss: 0.2958\n",
            "Current iteration: 3000, Loss: 0.2642\n",
            "Current iteration: 3500, Loss: 0.2395\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2201\n",
            "Current iteration: 4500, Loss: 0.2049\n",
            "Current iteration: 5000, Loss: 0.1932\n",
            "Current iteration: 5500, Loss: 0.1840\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1769\n",
            "Current iteration: 6500, Loss: 0.1715\n",
            "Current iteration: 7000, Loss: 0.1672\n",
            "Current iteration: 7500, Loss: 0.1640\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9743946509725696\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (38, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (45, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (54, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (44, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (56, 1))), Inequality(Expression(AFFINE, UNKNOWN, (2, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9698\n",
            "Current iteration: 500, Loss: 0.6483\n",
            "Current iteration: 1000, Loss: 0.5512\n",
            "Current iteration: 1500, Loss: 0.4934\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4529\n",
            "Current iteration: 2500, Loss: 0.4229\n",
            "Current iteration: 3000, Loss: 0.4001\n",
            "Current iteration: 3500, Loss: 0.3824\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3684\n",
            "Current iteration: 4500, Loss: 0.3572\n",
            "Current iteration: 5000, Loss: 0.3482\n",
            "Current iteration: 5500, Loss: 0.3408\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3347\n",
            "Current iteration: 6500, Loss: 0.3298\n",
            "Current iteration: 7000, Loss: 0.3257\n",
            "Current iteration: 7500, Loss: 0.3223\n",
            "For data_combine correlation of W and Wsvm:  0.9272440772344247\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 12\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (18, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9409\n",
            "Current iteration: 500, Loss: 0.5011\n",
            "Current iteration: 1000, Loss: 0.3627\n",
            "Current iteration: 1500, Loss: 0.2893\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2433\n",
            "Current iteration: 2500, Loss: 0.2135\n",
            "Current iteration: 3000, Loss: 0.1942\n",
            "Current iteration: 3500, Loss: 0.1818\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1739\n",
            "Current iteration: 4500, Loss: 0.1688\n",
            "Current iteration: 5000, Loss: 0.1656\n",
            "Current iteration: 5500, Loss: 0.1636\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1623\n",
            "Current iteration: 6500, Loss: 0.1615\n",
            "Current iteration: 7000, Loss: 0.1610\n",
            "Current iteration: 7500, Loss: 0.1608\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9900354508998233\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (4, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0078\n",
            "Current iteration: 500, Loss: 0.5543\n",
            "Current iteration: 1000, Loss: 0.3964\n",
            "Current iteration: 1500, Loss: 0.3089\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2539\n",
            "Current iteration: 2500, Loss: 0.2168\n",
            "Current iteration: 3000, Loss: 0.1910\n",
            "Current iteration: 3500, Loss: 0.1727\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1598\n",
            "Current iteration: 4500, Loss: 0.1507\n",
            "Current iteration: 5000, Loss: 0.1443\n",
            "Current iteration: 5500, Loss: 0.1399\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1367\n",
            "Current iteration: 6500, Loss: 0.1345\n",
            "Current iteration: 7000, Loss: 0.1330\n",
            "Current iteration: 7500, Loss: 0.1319\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9766802336504528\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (35, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9126\n",
            "Current iteration: 500, Loss: 0.5815\n",
            "Current iteration: 1000, Loss: 0.4703\n",
            "Current iteration: 1500, Loss: 0.4058\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3663\n",
            "Current iteration: 2500, Loss: 0.3411\n",
            "Current iteration: 3000, Loss: 0.3244\n",
            "Current iteration: 3500, Loss: 0.3129\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3048\n",
            "Current iteration: 4500, Loss: 0.2991\n",
            "Current iteration: 5000, Loss: 0.2951\n",
            "Current iteration: 5500, Loss: 0.2923\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2904\n",
            "Current iteration: 6500, Loss: 0.2890\n",
            "Current iteration: 7000, Loss: 0.2880\n",
            "Current iteration: 7500, Loss: 0.2873\n",
            "For data_combine correlation of W and Wsvm:  0.9575259301336455\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 13\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (23, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (31, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9846\n",
            "Current iteration: 500, Loss: 0.5500\n",
            "Current iteration: 1000, Loss: 0.4011\n",
            "Current iteration: 1500, Loss: 0.3290\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2851\n",
            "Current iteration: 2500, Loss: 0.2568\n",
            "Current iteration: 3000, Loss: 0.2382\n",
            "Current iteration: 3500, Loss: 0.2259\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2179\n",
            "Current iteration: 4500, Loss: 0.2127\n",
            "Current iteration: 5000, Loss: 0.2093\n",
            "Current iteration: 5500, Loss: 0.2070\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2056\n",
            "Current iteration: 6500, Loss: 0.2046\n",
            "Current iteration: 7000, Loss: 0.2040\n",
            "Current iteration: 7500, Loss: 0.2037\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9788436424491177\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (45, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0570\n",
            "Current iteration: 500, Loss: 0.5584\n",
            "Current iteration: 1000, Loss: 0.3782\n",
            "Current iteration: 1500, Loss: 0.2797\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2167\n",
            "Current iteration: 2500, Loss: 0.1740\n",
            "Current iteration: 3000, Loss: 0.1441\n",
            "Current iteration: 3500, Loss: 0.1231\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1083\n",
            "Current iteration: 4500, Loss: 0.0979\n",
            "Current iteration: 5000, Loss: 0.0906\n",
            "Current iteration: 5500, Loss: 0.0856\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.0820\n",
            "Current iteration: 6500, Loss: 0.0796\n",
            "Current iteration: 7000, Loss: 0.0779\n",
            "Current iteration: 7500, Loss: 0.0767\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9825493677525294\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (37, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (43, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (53, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (26, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (25, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (48, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (51, 1))), Inequality(Expression(AFFINE, UNKNOWN, (50, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0018\n",
            "Current iteration: 500, Loss: 0.5955\n",
            "Current iteration: 1000, Loss: 0.4771\n",
            "Current iteration: 1500, Loss: 0.4251\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3953\n",
            "Current iteration: 2500, Loss: 0.3756\n",
            "Current iteration: 3000, Loss: 0.3622\n",
            "Current iteration: 3500, Loss: 0.3529\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3464\n",
            "Current iteration: 4500, Loss: 0.3420\n",
            "Current iteration: 5000, Loss: 0.3389\n",
            "Current iteration: 5500, Loss: 0.3367\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3352\n",
            "Current iteration: 6500, Loss: 0.3342\n",
            "Current iteration: 7000, Loss: 0.3335\n",
            "Current iteration: 7500, Loss: 0.3331\n",
            "For data_combine correlation of W and Wsvm:  0.9565696748586399\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 14\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (18, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9743\n",
            "Current iteration: 500, Loss: 0.4924\n",
            "Current iteration: 1000, Loss: 0.3358\n",
            "Current iteration: 1500, Loss: 0.2509\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.1973\n",
            "Current iteration: 2500, Loss: 0.1622\n",
            "Current iteration: 3000, Loss: 0.1390\n",
            "Current iteration: 3500, Loss: 0.1236\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1134\n",
            "Current iteration: 4500, Loss: 0.1065\n",
            "Current iteration: 5000, Loss: 0.1020\n",
            "Current iteration: 5500, Loss: 0.0989\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.0968\n",
            "Current iteration: 6500, Loss: 0.0954\n",
            "Current iteration: 7000, Loss: 0.0945\n",
            "Current iteration: 7500, Loss: 0.0939\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9779529865277479\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.8719\n",
            "Current iteration: 500, Loss: 0.5410\n",
            "Current iteration: 1000, Loss: 0.4132\n",
            "Current iteration: 1500, Loss: 0.3326\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2780\n",
            "Current iteration: 2500, Loss: 0.2401\n",
            "Current iteration: 3000, Loss: 0.2137\n",
            "Current iteration: 3500, Loss: 0.1955\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1831\n",
            "Current iteration: 4500, Loss: 0.1745\n",
            "Current iteration: 5000, Loss: 0.1687\n",
            "Current iteration: 5500, Loss: 0.1648\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1621\n",
            "Current iteration: 6500, Loss: 0.1602\n",
            "Current iteration: 7000, Loss: 0.1590\n",
            "Current iteration: 7500, Loss: 0.1581\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9719488517831733\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (47, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (19, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (31, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (34, 1))), Inequality(Expression(AFFINE, UNKNOWN, (34, 1))), Inequality(Expression(AFFINE, UNKNOWN, (43, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (46, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (34, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9507\n",
            "Current iteration: 500, Loss: 0.5896\n",
            "Current iteration: 1000, Loss: 0.4901\n",
            "Current iteration: 1500, Loss: 0.4312\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3905\n",
            "Current iteration: 2500, Loss: 0.3607\n",
            "Current iteration: 3000, Loss: 0.3380\n",
            "Current iteration: 3500, Loss: 0.3204\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3067\n",
            "Current iteration: 4500, Loss: 0.2960\n",
            "Current iteration: 5000, Loss: 0.2876\n",
            "Current iteration: 5500, Loss: 0.2812\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2761\n",
            "Current iteration: 6500, Loss: 0.2722\n",
            "Current iteration: 7000, Loss: 0.2692\n",
            "Current iteration: 7500, Loss: 0.2669\n",
            "For data_combine correlation of W and Wsvm:  0.9558545897271661\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 15\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (21, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (2, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9936\n",
            "Current iteration: 500, Loss: 0.5676\n",
            "Current iteration: 1000, Loss: 0.4277\n",
            "Current iteration: 1500, Loss: 0.3552\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3108\n",
            "Current iteration: 2500, Loss: 0.2814\n",
            "Current iteration: 3000, Loss: 0.2611\n",
            "Current iteration: 3500, Loss: 0.2467\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2364\n",
            "Current iteration: 4500, Loss: 0.2290\n",
            "Current iteration: 5000, Loss: 0.2236\n",
            "Current iteration: 5500, Loss: 0.2198\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2170\n",
            "Current iteration: 6500, Loss: 0.2150\n",
            "Current iteration: 7000, Loss: 0.2136\n",
            "Current iteration: 7500, Loss: 0.2126\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9680107598534685\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9241\n",
            "Current iteration: 500, Loss: 0.5422\n",
            "Current iteration: 1000, Loss: 0.4082\n",
            "Current iteration: 1500, Loss: 0.3459\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3084\n",
            "Current iteration: 2500, Loss: 0.2834\n",
            "Current iteration: 3000, Loss: 0.2664\n",
            "Current iteration: 3500, Loss: 0.2548\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2470\n",
            "Current iteration: 4500, Loss: 0.2417\n",
            "Current iteration: 5000, Loss: 0.2382\n",
            "Current iteration: 5500, Loss: 0.2358\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2342\n",
            "Current iteration: 6500, Loss: 0.2331\n",
            "Current iteration: 7000, Loss: 0.2324\n",
            "Current iteration: 7500, Loss: 0.2320\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9803901140510485\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (38, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (45, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (39, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (60, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (35, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (44, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (1, 1))), Inequality(Expression(AFFINE, UNKNOWN, (34, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (2, 1))), Inequality(Expression(AFFINE, UNKNOWN, (43, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9612\n",
            "Current iteration: 500, Loss: 0.6127\n",
            "Current iteration: 1000, Loss: 0.5184\n",
            "Current iteration: 1500, Loss: 0.4771\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4524\n",
            "Current iteration: 2500, Loss: 0.4364\n",
            "Current iteration: 3000, Loss: 0.4253\n",
            "Current iteration: 3500, Loss: 0.4173\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.4114\n",
            "Current iteration: 4500, Loss: 0.4069\n",
            "Current iteration: 5000, Loss: 0.4036\n",
            "Current iteration: 5500, Loss: 0.4010\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3991\n",
            "Current iteration: 6500, Loss: 0.3977\n",
            "Current iteration: 7000, Loss: 0.3966\n",
            "Current iteration: 7500, Loss: 0.3958\n",
            "For data_combine correlation of W and Wsvm:  0.9457861063405963\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 16\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (37, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0224\n",
            "Current iteration: 500, Loss: 0.5698\n",
            "Current iteration: 1000, Loss: 0.4404\n",
            "Current iteration: 1500, Loss: 0.3776\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3399\n",
            "Current iteration: 2500, Loss: 0.3155\n",
            "Current iteration: 3000, Loss: 0.2989\n",
            "Current iteration: 3500, Loss: 0.2875\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2795\n",
            "Current iteration: 4500, Loss: 0.2739\n",
            "Current iteration: 5000, Loss: 0.2699\n",
            "Current iteration: 5500, Loss: 0.2671\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2651\n",
            "Current iteration: 6500, Loss: 0.2636\n",
            "Current iteration: 7000, Loss: 0.2626\n",
            "Current iteration: 7500, Loss: 0.2619\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9608305995995272\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (34, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0263\n",
            "Current iteration: 500, Loss: 0.5758\n",
            "Current iteration: 1000, Loss: 0.4072\n",
            "Current iteration: 1500, Loss: 0.3154\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2581\n",
            "Current iteration: 2500, Loss: 0.2211\n",
            "Current iteration: 3000, Loss: 0.1971\n",
            "Current iteration: 3500, Loss: 0.1816\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1717\n",
            "Current iteration: 4500, Loss: 0.1654\n",
            "Current iteration: 5000, Loss: 0.1613\n",
            "Current iteration: 5500, Loss: 0.1587\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1570\n",
            "Current iteration: 6500, Loss: 0.1560\n",
            "Current iteration: 7000, Loss: 0.1553\n",
            "Current iteration: 7500, Loss: 0.1550\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9776148355260033\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (27, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (38, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (64, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (42, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (43, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9952\n",
            "Current iteration: 500, Loss: 0.6303\n",
            "Current iteration: 1000, Loss: 0.5304\n",
            "Current iteration: 1500, Loss: 0.4812\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4500\n",
            "Current iteration: 2500, Loss: 0.4276\n",
            "Current iteration: 3000, Loss: 0.4108\n",
            "Current iteration: 3500, Loss: 0.3982\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3888\n",
            "Current iteration: 4500, Loss: 0.3818\n",
            "Current iteration: 5000, Loss: 0.3767\n",
            "Current iteration: 5500, Loss: 0.3730\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3703\n",
            "Current iteration: 6500, Loss: 0.3683\n",
            "Current iteration: 7000, Loss: 0.3668\n",
            "Current iteration: 7500, Loss: 0.3658\n",
            "For data_combine correlation of W and Wsvm:  0.9524624684289709\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 17\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9850\n",
            "Current iteration: 500, Loss: 0.5797\n",
            "Current iteration: 1000, Loss: 0.4539\n",
            "Current iteration: 1500, Loss: 0.3853\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3429\n",
            "Current iteration: 2500, Loss: 0.3158\n",
            "Current iteration: 3000, Loss: 0.2983\n",
            "Current iteration: 3500, Loss: 0.2869\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2795\n",
            "Current iteration: 4500, Loss: 0.2747\n",
            "Current iteration: 5000, Loss: 0.2715\n",
            "Current iteration: 5500, Loss: 0.2695\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2682\n",
            "Current iteration: 6500, Loss: 0.2673\n",
            "Current iteration: 7000, Loss: 0.2669\n",
            "Current iteration: 7500, Loss: 0.2666\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9689622009931548\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0644\n",
            "Current iteration: 500, Loss: 0.5588\n",
            "Current iteration: 1000, Loss: 0.3988\n",
            "Current iteration: 1500, Loss: 0.3152\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2612\n",
            "Current iteration: 2500, Loss: 0.2230\n",
            "Current iteration: 3000, Loss: 0.1953\n",
            "Current iteration: 3500, Loss: 0.1751\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1606\n",
            "Current iteration: 4500, Loss: 0.1501\n",
            "Current iteration: 5000, Loss: 0.1426\n",
            "Current iteration: 5500, Loss: 0.1373\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1334\n",
            "Current iteration: 6500, Loss: 0.1307\n",
            "Current iteration: 7000, Loss: 0.1287\n",
            "Current iteration: 7500, Loss: 0.1273\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9718588603117343\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (39, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (36, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (43, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (5, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9859\n",
            "Current iteration: 500, Loss: 0.5965\n",
            "Current iteration: 1000, Loss: 0.4819\n",
            "Current iteration: 1500, Loss: 0.4256\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3916\n",
            "Current iteration: 2500, Loss: 0.3682\n",
            "Current iteration: 3000, Loss: 0.3513\n",
            "Current iteration: 3500, Loss: 0.3388\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3294\n",
            "Current iteration: 4500, Loss: 0.3223\n",
            "Current iteration: 5000, Loss: 0.3169\n",
            "Current iteration: 5500, Loss: 0.3129\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3100\n",
            "Current iteration: 6500, Loss: 0.3078\n",
            "Current iteration: 7000, Loss: 0.3061\n",
            "Current iteration: 7500, Loss: 0.3049\n",
            "For data_combine correlation of W and Wsvm:  0.9475654180037203\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 18\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9850\n",
            "Current iteration: 500, Loss: 0.5655\n",
            "Current iteration: 1000, Loss: 0.4278\n",
            "Current iteration: 1500, Loss: 0.3435\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2853\n",
            "Current iteration: 2500, Loss: 0.2433\n",
            "Current iteration: 3000, Loss: 0.2123\n",
            "Current iteration: 3500, Loss: 0.1889\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1712\n",
            "Current iteration: 4500, Loss: 0.1576\n",
            "Current iteration: 5000, Loss: 0.1471\n",
            "Current iteration: 5500, Loss: 0.1390\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1327\n",
            "Current iteration: 6500, Loss: 0.1279\n",
            "Current iteration: 7000, Loss: 0.1241\n",
            "Current iteration: 7500, Loss: 0.1211\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9696623201003292\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (14, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9998\n",
            "Current iteration: 500, Loss: 0.5956\n",
            "Current iteration: 1000, Loss: 0.4625\n",
            "Current iteration: 1500, Loss: 0.3758\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3144\n",
            "Current iteration: 2500, Loss: 0.2709\n",
            "Current iteration: 3000, Loss: 0.2401\n",
            "Current iteration: 3500, Loss: 0.2182\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2025\n",
            "Current iteration: 4500, Loss: 0.1912\n",
            "Current iteration: 5000, Loss: 0.1831\n",
            "Current iteration: 5500, Loss: 0.1773\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1731\n",
            "Current iteration: 6500, Loss: 0.1700\n",
            "Current iteration: 7000, Loss: 0.1679\n",
            "Current iteration: 7500, Loss: 0.1663\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9640434447611943\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (55, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (22, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (19, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (40, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1))), Inequality(Expression(AFFINE, UNKNOWN, (54, 1))), Inequality(Expression(AFFINE, UNKNOWN, (56, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0138\n",
            "Current iteration: 500, Loss: 0.6329\n",
            "Current iteration: 1000, Loss: 0.5328\n",
            "Current iteration: 1500, Loss: 0.4678\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4223\n",
            "Current iteration: 2500, Loss: 0.3892\n",
            "Current iteration: 3000, Loss: 0.3640\n",
            "Current iteration: 3500, Loss: 0.3444\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3286\n",
            "Current iteration: 4500, Loss: 0.3158\n",
            "Current iteration: 5000, Loss: 0.3053\n",
            "Current iteration: 5500, Loss: 0.2966\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2894\n",
            "Current iteration: 6500, Loss: 0.2834\n",
            "Current iteration: 7000, Loss: 0.2785\n",
            "Current iteration: 7500, Loss: 0.2745\n",
            "For data_combine correlation of W and Wsvm:  0.9102167747280677\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 19\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9359\n",
            "Current iteration: 500, Loss: 0.5969\n",
            "Current iteration: 1000, Loss: 0.4836\n",
            "Current iteration: 1500, Loss: 0.4156\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3664\n",
            "Current iteration: 2500, Loss: 0.3278\n",
            "Current iteration: 3000, Loss: 0.2964\n",
            "Current iteration: 3500, Loss: 0.2706\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2492\n",
            "Current iteration: 4500, Loss: 0.2315\n",
            "Current iteration: 5000, Loss: 0.2169\n",
            "Current iteration: 5500, Loss: 0.2048\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1948\n",
            "Current iteration: 6500, Loss: 0.1866\n",
            "Current iteration: 7000, Loss: 0.1799\n",
            "Current iteration: 7500, Loss: 0.1743\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9827758885499442\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (37, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9816\n",
            "Current iteration: 500, Loss: 0.5966\n",
            "Current iteration: 1000, Loss: 0.4617\n",
            "Current iteration: 1500, Loss: 0.3826\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3268\n",
            "Current iteration: 2500, Loss: 0.2847\n",
            "Current iteration: 3000, Loss: 0.2520\n",
            "Current iteration: 3500, Loss: 0.2263\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2060\n",
            "Current iteration: 4500, Loss: 0.1899\n",
            "Current iteration: 5000, Loss: 0.1771\n",
            "Current iteration: 5500, Loss: 0.1671\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1591\n",
            "Current iteration: 6500, Loss: 0.1529\n",
            "Current iteration: 7000, Loss: 0.1480\n",
            "Current iteration: 7500, Loss: 0.1442\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9595518543792714\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (40, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (37, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (41, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (33, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (39, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (31, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (17, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (57, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (42, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9538\n",
            "Current iteration: 500, Loss: 0.6656\n",
            "Current iteration: 1000, Loss: 0.5853\n",
            "Current iteration: 1500, Loss: 0.5400\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.5093\n",
            "Current iteration: 2500, Loss: 0.4865\n",
            "Current iteration: 3000, Loss: 0.4685\n",
            "Current iteration: 3500, Loss: 0.4536\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.4410\n",
            "Current iteration: 4500, Loss: 0.4302\n",
            "Current iteration: 5000, Loss: 0.4210\n",
            "Current iteration: 5500, Loss: 0.4129\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.4060\n",
            "Current iteration: 6500, Loss: 0.4000\n",
            "Current iteration: 7000, Loss: 0.3949\n",
            "Current iteration: 7500, Loss: 0.3904\n",
            "For data_combine correlation of W and Wsvm:  0.9196919230672997\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 20\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (20, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (31, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0367\n",
            "Current iteration: 500, Loss: 0.5870\n",
            "Current iteration: 1000, Loss: 0.4237\n",
            "Current iteration: 1500, Loss: 0.3358\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2831\n",
            "Current iteration: 2500, Loss: 0.2498\n",
            "Current iteration: 3000, Loss: 0.2285\n",
            "Current iteration: 3500, Loss: 0.2150\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2066\n",
            "Current iteration: 4500, Loss: 0.2014\n",
            "Current iteration: 5000, Loss: 0.1982\n",
            "Current iteration: 5500, Loss: 0.1962\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1950\n",
            "Current iteration: 6500, Loss: 0.1942\n",
            "Current iteration: 7000, Loss: 0.1939\n",
            "Current iteration: 7500, Loss: 0.1937\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9841336000826236\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (37, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9943\n",
            "Current iteration: 500, Loss: 0.5689\n",
            "Current iteration: 1000, Loss: 0.4182\n",
            "Current iteration: 1500, Loss: 0.3377\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2862\n",
            "Current iteration: 2500, Loss: 0.2503\n",
            "Current iteration: 3000, Loss: 0.2244\n",
            "Current iteration: 3500, Loss: 0.2055\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1918\n",
            "Current iteration: 4500, Loss: 0.1820\n",
            "Current iteration: 5000, Loss: 0.1749\n",
            "Current iteration: 5500, Loss: 0.1698\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1662\n",
            "Current iteration: 6500, Loss: 0.1636\n",
            "Current iteration: 7000, Loss: 0.1618\n",
            "Current iteration: 7500, Loss: 0.1605\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9769024539271745\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (77, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (37, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (30, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (51, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (3, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (4, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (37, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0236\n",
            "Current iteration: 500, Loss: 0.6377\n",
            "Current iteration: 1000, Loss: 0.5229\n",
            "Current iteration: 1500, Loss: 0.4683\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4365\n",
            "Current iteration: 2500, Loss: 0.4152\n",
            "Current iteration: 3000, Loss: 0.3997\n",
            "Current iteration: 3500, Loss: 0.3879\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3791\n",
            "Current iteration: 4500, Loss: 0.3726\n",
            "Current iteration: 5000, Loss: 0.3680\n",
            "Current iteration: 5500, Loss: 0.3647\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3625\n",
            "Current iteration: 6500, Loss: 0.3610\n",
            "Current iteration: 7000, Loss: 0.3600\n",
            "Current iteration: 7500, Loss: 0.3594\n",
            "For data_combine correlation of W and Wsvm:  0.9500641381690756\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 21\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9552\n",
            "Current iteration: 500, Loss: 0.5185\n",
            "Current iteration: 1000, Loss: 0.3610\n",
            "Current iteration: 1500, Loss: 0.2731\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2167\n",
            "Current iteration: 2500, Loss: 0.1795\n",
            "Current iteration: 3000, Loss: 0.1547\n",
            "Current iteration: 3500, Loss: 0.1383\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1273\n",
            "Current iteration: 4500, Loss: 0.1200\n",
            "Current iteration: 5000, Loss: 0.1152\n",
            "Current iteration: 5500, Loss: 0.1119\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1097\n",
            "Current iteration: 6500, Loss: 0.1083\n",
            "Current iteration: 7000, Loss: 0.1073\n",
            "Current iteration: 7500, Loss: 0.1066\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9792675918599637\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (13, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9233\n",
            "Current iteration: 500, Loss: 0.5353\n",
            "Current iteration: 1000, Loss: 0.3911\n",
            "Current iteration: 1500, Loss: 0.3095\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2563\n",
            "Current iteration: 2500, Loss: 0.2193\n",
            "Current iteration: 3000, Loss: 0.1930\n",
            "Current iteration: 3500, Loss: 0.1744\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1612\n",
            "Current iteration: 4500, Loss: 0.1520\n",
            "Current iteration: 5000, Loss: 0.1455\n",
            "Current iteration: 5500, Loss: 0.1409\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1377\n",
            "Current iteration: 6500, Loss: 0.1355\n",
            "Current iteration: 7000, Loss: 0.1340\n",
            "Current iteration: 7500, Loss: 0.1329\n",
            "For data_topic_2 correlation of W and Wsvm:  0.976341565811149\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (80, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (63, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (4, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (34, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1))), Inequality(Expression(AFFINE, UNKNOWN, (25, 1))), Inequality(Expression(AFFINE, UNKNOWN, (39, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (31, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (23, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9457\n",
            "Current iteration: 500, Loss: 0.5995\n",
            "Current iteration: 1000, Loss: 0.5038\n",
            "Current iteration: 1500, Loss: 0.4529\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4193\n",
            "Current iteration: 2500, Loss: 0.3949\n",
            "Current iteration: 3000, Loss: 0.3762\n",
            "Current iteration: 3500, Loss: 0.3614\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3493\n",
            "Current iteration: 4500, Loss: 0.3394\n",
            "Current iteration: 5000, Loss: 0.3312\n",
            "Current iteration: 5500, Loss: 0.3244\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3187\n",
            "Current iteration: 6500, Loss: 0.3140\n",
            "Current iteration: 7000, Loss: 0.3101\n",
            "Current iteration: 7500, Loss: 0.3069\n",
            "For data_combine correlation of W and Wsvm:  0.9588626711640744\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 22\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0672\n",
            "Current iteration: 500, Loss: 0.6264\n",
            "Current iteration: 1000, Loss: 0.4839\n",
            "Current iteration: 1500, Loss: 0.3984\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3373\n",
            "Current iteration: 2500, Loss: 0.2914\n",
            "Current iteration: 3000, Loss: 0.2561\n",
            "Current iteration: 3500, Loss: 0.2285\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2068\n",
            "Current iteration: 4500, Loss: 0.1898\n",
            "Current iteration: 5000, Loss: 0.1764\n",
            "Current iteration: 5500, Loss: 0.1659\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1577\n",
            "Current iteration: 6500, Loss: 0.1512\n",
            "Current iteration: 7000, Loss: 0.1461\n",
            "Current iteration: 7500, Loss: 0.1422\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9816557890855744\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (9, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (24, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (1, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0342\n",
            "Current iteration: 500, Loss: 0.6366\n",
            "Current iteration: 1000, Loss: 0.5009\n",
            "Current iteration: 1500, Loss: 0.4214\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3681\n",
            "Current iteration: 2500, Loss: 0.3294\n",
            "Current iteration: 3000, Loss: 0.3000\n",
            "Current iteration: 3500, Loss: 0.2773\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2597\n",
            "Current iteration: 4500, Loss: 0.2459\n",
            "Current iteration: 5000, Loss: 0.2351\n",
            "Current iteration: 5500, Loss: 0.2266\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2200\n",
            "Current iteration: 6500, Loss: 0.2147\n",
            "Current iteration: 7000, Loss: 0.2105\n",
            "Current iteration: 7500, Loss: 0.2072\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9559701203811721\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (20, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (23, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (15, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (53, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (18, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (35, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (9, 1))), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (7, 1))), Inequality(Expression(AFFINE, UNKNOWN, (53, 1))), Inequality(Expression(AFFINE, UNKNOWN, (36, 1))), Inequality(Expression(AFFINE, UNKNOWN, (46, 1))), Inequality(Expression(AFFINE, UNKNOWN, (46, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0644\n",
            "Current iteration: 500, Loss: 0.6816\n",
            "Current iteration: 1000, Loss: 0.5767\n",
            "Current iteration: 1500, Loss: 0.5190\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4790\n",
            "Current iteration: 2500, Loss: 0.4486\n",
            "Current iteration: 3000, Loss: 0.4245\n",
            "Current iteration: 3500, Loss: 0.4051\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3895\n",
            "Current iteration: 4500, Loss: 0.3768\n",
            "Current iteration: 5000, Loss: 0.3665\n",
            "Current iteration: 5500, Loss: 0.3582\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3516\n",
            "Current iteration: 6500, Loss: 0.3462\n",
            "Current iteration: 7000, Loss: 0.3420\n",
            "Current iteration: 7500, Loss: 0.3386\n",
            "For data_combine correlation of W and Wsvm:  0.9371590660688344\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 23\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (18, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (34, 1))), Inequality(Expression(AFFINE, UNKNOWN, (31, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0325\n",
            "Current iteration: 500, Loss: 0.5796\n",
            "Current iteration: 1000, Loss: 0.4048\n",
            "Current iteration: 1500, Loss: 0.3021\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2354\n",
            "Current iteration: 2500, Loss: 0.1903\n",
            "Current iteration: 3000, Loss: 0.1593\n",
            "Current iteration: 3500, Loss: 0.1381\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1235\n",
            "Current iteration: 4500, Loss: 0.1136\n",
            "Current iteration: 5000, Loss: 0.1069\n",
            "Current iteration: 5500, Loss: 0.1023\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.0992\n",
            "Current iteration: 6500, Loss: 0.0971\n",
            "Current iteration: 7000, Loss: 0.0957\n",
            "Current iteration: 7500, Loss: 0.0948\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9781834048597613\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (18, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (30, 1))), Inequality(Expression(AFFINE, UNKNOWN, (18, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (2, 1))), Inequality(Expression(AFFINE, UNKNOWN, (19, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (24, 1))), Inequality(Expression(AFFINE, UNKNOWN, (41, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9818\n",
            "Current iteration: 500, Loss: 0.6105\n",
            "Current iteration: 1000, Loss: 0.4535\n",
            "Current iteration: 1500, Loss: 0.3518\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2807\n",
            "Current iteration: 2500, Loss: 0.2296\n",
            "Current iteration: 3000, Loss: 0.1925\n",
            "Current iteration: 3500, Loss: 0.1655\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1458\n",
            "Current iteration: 4500, Loss: 0.1315\n",
            "Current iteration: 5000, Loss: 0.1210\n",
            "Current iteration: 5500, Loss: 0.1134\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1079\n",
            "Current iteration: 6500, Loss: 0.1039\n",
            "Current iteration: 7000, Loss: 0.1010\n",
            "Current iteration: 7500, Loss: 0.0989\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9802407644197085\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (29, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (16, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (13, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (35, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (38, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (46, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (21, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (58, 1))), Inequality(Expression(AFFINE, UNKNOWN, (35, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (40, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0691\n",
            "Current iteration: 500, Loss: 0.6614\n",
            "Current iteration: 1000, Loss: 0.5333\n",
            "Current iteration: 1500, Loss: 0.4619\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4150\n",
            "Current iteration: 2500, Loss: 0.3815\n",
            "Current iteration: 3000, Loss: 0.3562\n",
            "Current iteration: 3500, Loss: 0.3365\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3210\n",
            "Current iteration: 4500, Loss: 0.3086\n",
            "Current iteration: 5000, Loss: 0.2987\n",
            "Current iteration: 5500, Loss: 0.2907\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2844\n",
            "Current iteration: 6500, Loss: 0.2794\n",
            "Current iteration: 7000, Loss: 0.2754\n",
            "Current iteration: 7500, Loss: 0.2723\n",
            "For data_combine correlation of W and Wsvm:  0.913123985988983\n",
            "----------------------------\n",
            "\n",
            "********************************************\n",
            "Current epoch: 24\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (11, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (10, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (2, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (7, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (27, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (16, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9565\n",
            "Current iteration: 500, Loss: 0.5292\n",
            "Current iteration: 1000, Loss: 0.3751\n",
            "Current iteration: 1500, Loss: 0.2930\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.2462\n",
            "Current iteration: 2500, Loss: 0.2189\n",
            "Current iteration: 3000, Loss: 0.2030\n",
            "Current iteration: 3500, Loss: 0.1935\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.1880\n",
            "Current iteration: 4500, Loss: 0.1847\n",
            "Current iteration: 5000, Loss: 0.1828\n",
            "Current iteration: 5500, Loss: 0.1817\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.1811\n",
            "Current iteration: 6500, Loss: 0.1808\n",
            "Current iteration: 7000, Loss: 0.1806\n",
            "Current iteration: 7500, Loss: 0.1805\n",
            "For data_topic_1 correlation of W and Wsvm:  0.9842458272266665\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (3, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (31, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (8, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (20, 1))), Inequality(Expression(AFFINE, UNKNOWN, (11, 1))), Inequality(Expression(AFFINE, UNKNOWN, (15, 1))), Inequality(Expression(AFFINE, UNKNOWN, (26, 1))), Inequality(Expression(AFFINE, UNKNOWN, (28, 1))), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (22, 1))), Inequality(Expression(AFFINE, UNKNOWN, (6, 1))), Inequality(Expression(AFFINE, UNKNOWN, (12, 1))), Inequality(Expression(AFFINE, UNKNOWN, (29, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 1.0111\n",
            "Current iteration: 500, Loss: 0.5815\n",
            "Current iteration: 1000, Loss: 0.4341\n",
            "Current iteration: 1500, Loss: 0.3514\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.3002\n",
            "Current iteration: 2500, Loss: 0.2672\n",
            "Current iteration: 3000, Loss: 0.2457\n",
            "Current iteration: 3500, Loss: 0.2316\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.2226\n",
            "Current iteration: 4500, Loss: 0.2167\n",
            "Current iteration: 5000, Loss: 0.2129\n",
            "Current iteration: 5500, Loss: 0.2105\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.2090\n",
            "Current iteration: 6500, Loss: 0.2080\n",
            "Current iteration: 7000, Loss: 0.2075\n",
            "Current iteration: 7500, Loss: 0.2072\n",
            "For data_topic_2 correlation of W and Wsvm:  0.9807745775055662\n",
            "----------------------------\n",
            "try - prob is NOT DCP: True\n",
            "try - constraints: [Equality(Expression(AFFINE, UNKNOWN, (28, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (5, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (46, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (6, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (12, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (26, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (55, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (38, 1)), Constant(CONSTANT, ZERO, ())), Equality(Expression(AFFINE, UNKNOWN, (37, 1)), Constant(CONSTANT, ZERO, ())), Inequality(Expression(AFFINE, UNKNOWN, (17, 1))), Inequality(Expression(AFFINE, UNKNOWN, (33, 1))), Inequality(Expression(AFFINE, UNKNOWN, (32, 1))), Inequality(Expression(AFFINE, UNKNOWN, (8, 1))), Inequality(Expression(AFFINE, UNKNOWN, (38, 1))), Inequality(Expression(AFFINE, UNKNOWN, (43, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (10, 1))), Inequality(Expression(AFFINE, UNKNOWN, (14, 1)))]\n",
            "try - prob.status: None\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 0, Loss: 0.9898\n",
            "Current iteration: 500, Loss: 0.6166\n",
            "Current iteration: 1000, Loss: 0.5115\n",
            "Current iteration: 1500, Loss: 0.4611\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 2000, Loss: 0.4323\n",
            "Current iteration: 2500, Loss: 0.4142\n",
            "Current iteration: 3000, Loss: 0.4024\n",
            "Current iteration: 3500, Loss: 0.3945\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 4000, Loss: 0.3894\n",
            "Current iteration: 4500, Loss: 0.3860\n",
            "Current iteration: 5000, Loss: 0.3839\n",
            "Current iteration: 5500, Loss: 0.3826\n",
            "Norm of grad:  tensor(1.0000, dtype=torch.float64)\n",
            "Current iteration: 6000, Loss: 0.3818\n",
            "Current iteration: 6500, Loss: 0.3814\n",
            "Current iteration: 7000, Loss: 0.3811\n",
            "Current iteration: 7500, Loss: 0.3810\n",
            "For data_combine correlation of W and Wsvm:  0.9705790806272492\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Section 1. Get W^{svm} and W(\\tau) for each data\n",
        "\n",
        "\"\"\"\n",
        "dlist = [8]\n",
        "di = len(dlist) -1\n",
        "initial_n = 100  # Number of sequence in each dataset\n",
        "\n",
        "training_datasets = ['data_topic_1', 'data_topic_2', 'data_combine']\n",
        "testing_datasets = ['test_topic_1', 'test_topic_2', 'test_combine']\n",
        "\n",
        "attn_probs_values = {}\n",
        "Wi_norm_list_values = {}\n",
        "dict_token_epochs = {}\n",
        "\n",
        "# for training data\n",
        "data_epochs = {}\n",
        "X_epochs = {}\n",
        "z_epochs = {}\n",
        "scc_klst_epochs = {}\n",
        "\n",
        "# for testing data\n",
        "test_data_epochs_T = {}\n",
        "test_data_epochs_test_T = {}\n",
        "\n",
        "\n",
        "# training results\n",
        "last_W_epochs = {} # save last W(\\tau) of each epoch\n",
        "sol_cvx_list_epochs = {} # save the W^{svm} of each epoch\n",
        "W_tau_epochs = {} # save W(\\tau) for each epoch\n",
        "W_svm_epochs = {}\n",
        "corr_list_values = {} # save correlation results for each epoch\n",
        "\n",
        "theor_tpgs_epochs = {}  # save theoretical tpgs (before generating input data)\n",
        "empir_tpgs_epochs ={} # save empirical tpgs (based on the genereated input data)\n",
        "theor_graph_epochs = {} # save gragh of theoretical tpgs\n",
        "empir_graph_epochs = {} # save gragh of empirical tpgs\n",
        "\n",
        "for data in training_datasets:\n",
        "    attn_probs_values[data] = np.zeros((len(dlist), epochs, ITN))\n",
        "    corr_list_values[data] = np.zeros((len(dlist), 2, epochs, ITN))\n",
        "    Wi_norm_list_values[data] = np.zeros((nlayer, epochs, ITN))\n",
        "\n",
        "\n",
        "ei = 0\n",
        "results = []\n",
        "while ei < epochs:\n",
        "    n = initial_n\n",
        "    print(\"\\n********************************************\")\n",
        "    print(\"Current epoch:\", ei)\n",
        "\n",
        "    # ============ Part 1: generate Theoretical TPG for topic 1, topic 2, and combination ============\n",
        "    initial_tpgs_1, theor_tpgs_1, theor_Gs_1 = get_theor_tpgs_new(K,L) # topic 1\n",
        "    initial_tpgs_2, theor_tpgs_2, theor_Gs_2 = get_theor_tpgs_new(K,L) # topic 2\n",
        "\n",
        "    initial_tpgs_cb, theor_tpgs_cb, theor_Gs_cb = get_theor_tpgs_cb_new(theor_tpgs_1,theor_tpgs_2) # topic combine\n",
        "\n",
        "    theor_tpgs_epochs[ei] = {\n",
        "        'data_topic_1': theor_tpgs_1,\n",
        "        'data_topic_2': theor_tpgs_2,\n",
        "        'data_combine': theor_tpgs_cb\n",
        "        }\n",
        "\n",
        "    theor_graph_epochs[ei] = {\n",
        "        'data_topic_1': theor_Gs_1,\n",
        "        'data_topic_2': theor_Gs_2,\n",
        "        'data_combine': theor_Gs_cb\n",
        "        }\n",
        "\n",
        "\n",
        "    # ============ Part 2: generate data and get input paras for topic 1, topic 2, and combination ============\n",
        "    ## 2.1 get vocabulary and dict_token\n",
        "    Vocab, dict_token, pseudo_Vocab = get_vocab_dict(token_choice = token_choice, K = K, d = d)\n",
        "\n",
        "\n",
        "    dict_token_epochs[ei] = dict_token\n",
        "\n",
        "    ## 2.2 generate training data\n",
        "    data_topic_1 = generate_data(theor_tpgs_1, n, T) # topic 1\n",
        "    data_topic_2 = generate_data(theor_tpgs_2, n, T) # topic 2\n",
        "    data_combine = data_topic_1 + data_topic_2 # combine\n",
        "\n",
        "    data_epochs[ei] = {\n",
        "        'data_topic_1': data_topic_1,\n",
        "        'data_topic_2': data_topic_2,\n",
        "        'data_combine': data_combine\n",
        "        }\n",
        "\n",
        "    ## 2.3 Empirical TPG based on the input data\n",
        "    seq_classified_1, empir_tpgs_1, empir_Gs_1 = get_empir_tpgs(data_topic_1) # topic 1\n",
        "    seq_classified_2, empir_tpgs_2, empir_Gs_2 = get_empir_tpgs(data_topic_2) # topic 2\n",
        "    seq_classified_cb, empir_tpgs_cb, empir_Gs_cb = get_empir_tpgs(data_combine) # combination\n",
        "\n",
        "    empir_tpgs_epochs[ei] = {\n",
        "        'data_topic_1': empir_tpgs_1,\n",
        "        'data_topic_2': empir_tpgs_2,\n",
        "        'data_combine': empir_tpgs_cb\n",
        "        }\n",
        "\n",
        "    empir_graph_epochs[ei] = {\n",
        "        'data_topic_1': empir_Gs_1,\n",
        "        'data_topic_2': empir_Gs_2,\n",
        "        'data_combine': empir_Gs_cb\n",
        "        }\n",
        "\n",
        "    ## 2.4 Generate test data based on the empirical TPG\n",
        "    # test data with the T = 4\n",
        "    test_topic_1 = generate_data(empir_tpgs_1, n, T)\n",
        "    test_topic_2 = generate_data(empir_tpgs_2, n, T)\n",
        "    test_combine = test_topic_1 + test_topic_2\n",
        "\n",
        "    test_data_epochs_T[ei] = {\n",
        "        'test_topic_1': test_topic_1,\n",
        "        'test_topic_2': test_topic_2,\n",
        "        'test_combine': test_combine\n",
        "        }\n",
        "\n",
        "    # test data with the test_T = 8\n",
        "    test_topic_1_new = generate_data(empir_tpgs_1, n, test_T)\n",
        "    test_topic_2_new = generate_data(empir_tpgs_2, n, test_T)\n",
        "    test_combine_new = test_topic_1_new + test_topic_2_new\n",
        "    test_data_epochs_test_T[ei] = {\n",
        "        'test_topic_1': test_topic_1_new,\n",
        "        'test_topic_2': test_topic_2_new,\n",
        "        'test_combine': test_combine_new\n",
        "        }\n",
        "\n",
        "    # ============ Part 3: Calculate W^{svm} and W(\\tau) for each data ============\n",
        "\n",
        "    ## 3.1 input parameters needed\n",
        "    # Create dictionaries to store the returned values\n",
        "    X_values = {}\n",
        "    idx_token_values = {}\n",
        "    z_values = {}\n",
        "    idx_z_values = {}\n",
        "    C_alpha_values = {}\n",
        "    scc_klst_values = {}\n",
        "    adj_mat_values = {}\n",
        "    w_dir_values = {}\n",
        "    sol_cvx_list_values = {}\n",
        "    Wi_list_values = {}\n",
        "    Wi_list_save = {}\n",
        "    last_W_tau_values = {}\n",
        "    parameter_list = {}\n",
        "\n",
        "    for data in training_datasets:\n",
        "        if data == 'data_combine':\n",
        "            n = 2*initial_n\n",
        "        else:\n",
        "            n = initial_n\n",
        "\n",
        "        X, idx_token, z, idx_z, C_alpha, scc_klst, adj_mat = get_input_paras(eval(data), dict_token)\n",
        "\n",
        "        X_values[data] = X\n",
        "        idx_token_values[data] = idx_token\n",
        "        z_values[data] = z\n",
        "        idx_z_values[data] = idx_z\n",
        "        C_alpha_values[data] = C_alpha\n",
        "        scc_klst_values[data] = scc_klst\n",
        "        adj_mat_values[data] = adj_mat\n",
        "\n",
        "        ## 3.1 get W^{svm} for each data (w_dir_values[data] and sol_cvx_list_values[data][0])\n",
        "\n",
        "        w_dir_values[data] = W_svm_solver_cvxpy(Vocab, n, d, idx_z_values[data], idx_token_values[data],\n",
        "                                                    C_alpha_values[data], onetoken = False, wfin = False,\n",
        "                                                    adj_mat = adj_mat_values[data], scc_lst = scc_klst_values[data])\n",
        "\n",
        "        sol_cvx_list_values[data] = np.zeros((nlayer, d, d))\n",
        "        sol_cvx_list_values[data][0] =  normalize_sol(w_dir_values[data]) # normalized w_dir\n",
        "\n",
        "        if np.all(sol_cvx_list_values[data][0] == 0):\n",
        "            continue\n",
        "\n",
        "        ## 3.2 calculate W(\\tau)\n",
        "        model = MLayerAttn(d, regress = True, n_layer = nlayer, dim_t = T,\n",
        "                    identity_W=False, identity_V = True,\n",
        "                    factorize_W = factorize_w, init = initialize_w,\n",
        "                    skip = skip, layer_norm = layer_norm, avg_norm = avg_norm,\n",
        "            ).double()\n",
        "\n",
        "        parameter_list = get_para_list(factorize_w, layer_norm, avg_norm) # general_para_1\n",
        "\n",
        "        optimizer = torch.optim.SGD(parameter_list, lr=lr, ) # general_para_2\n",
        "\n",
        "        Wi_list_values[data] = np.zeros((nlayer, ITN, d, d)) # initialize Wi_list before training\n",
        "        Wi_list_save[data] = np.zeros((nlayer, ITN // 8, d, d)) # initialize Wi_list for saving\n",
        "\n",
        "        model = train_W(model, X_values[data], idx_token_values[data], z_values[data], token_choice, cls_choice, Vocab,\n",
        "                        C_alpha_values[data], nlayer, n, K, di, ei, ITN, toy_case, batch_toy, scc_klst,\n",
        "                        loss_type, optimizer, norm_grad, parameter_list,\n",
        "                        Wi_list = Wi_list_values[data], attn_probs = attn_probs_values[data], Wi_norm_list = Wi_norm_list_values[data],\n",
        "                        )\n",
        "\n",
        "        ## 3.3 get correlation between W^{svm} and each W(\\tau) (\\tau = 1, 2, ..., ITN)\n",
        "        for it in range(ITN):\n",
        "                    Wi_list_values[data][0, it] /= np.linalg.norm(Wi_list_values[data][0, it])\n",
        "                    if it % 8 == 0:\n",
        "                        Wi_list_save[data][0, it // 8] = Wi_list_values[data][0, it]\n",
        "                    if not separa:\n",
        "                        corr_list_values[data][di, 0, ei, it] = Wi_list_values[data][0, it].reshape(-1).dot(sol_cvx_list_values[data][di].reshape(-1))\n",
        "\n",
        "\n",
        "        last_W_tau_values[data] = Wi_list_values[data][0, ITN-1]\n",
        "\n",
        "        print(\"For\", data, \"correlation of W and Wsvm: \", corr_list_values[data][di, 0, ei, -1])\n",
        "        print(\"----------------------------\")\n",
        "\n",
        "\n",
        "    X_epochs[ei] = X_values\n",
        "    z_epochs[ei] = z_values\n",
        "    sol_cvx_list_epochs[ei] = sol_cvx_list_values\n",
        "    scc_klst_epochs[ei] = scc_klst_values\n",
        "    W_tau_epochs[ei] = Wi_list_values # shape (nlayer, ITN, d, d)\n",
        "    last_W_epochs[ei] = last_W_tau_values\n",
        "\n",
        "    # ============ Part 4: Save training results of each epoch ============\n",
        "\n",
        "    row_ei = {'current_epoch': ei, 'K': K, 'L': L, 'd': d, 'T': T, 'token_choice': token_choice, '#_seqs_epoch': initial_n, # parameters\n",
        "              'empir_TPG_12cb': empir_tpgs_epochs[ei], # empir_TPGs all (topic_1, topic_2, combine)\n",
        "              'dictionary': dict_token, # dictionary\n",
        "              'pseudo_Vocab': pseudo_Vocab, # pseudo_Vocab\n",
        "              'training_data': data_epochs[ei], # train data\n",
        "              'SCC_12cb': scc_klst_values,\n",
        "              'testing_data': test_data_epochs_T[ei], # test data with T = 4\n",
        "              'testing_data_new': test_data_epochs_test_T[ei], # test data with test_T = 8\n",
        "              'W_svm_12cb': sol_cvx_list_values, # W_svm all (topic_1, topic_2, combine)\n",
        "              'W_tau_12cb': Wi_list_save, # W_tau every 8\n",
        "              'last_W_12cb': last_W_tau_values,\n",
        "              'correlation_1': corr_list_values['data_topic_1'][di, 0, ei, :].tolist(),\n",
        "              'correlation_2': corr_list_values['data_topic_2'][di, 0, ei, :].tolist(),\n",
        "              'correlation_cb': corr_list_values['data_combine'][di, 0, ei, :].tolist()\n",
        "              }\n",
        "    results.append(row_ei)\n",
        "    ei += 1\n",
        "\n",
        "df_results = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBr_bxkCT2Bt"
      },
      "source": [
        "### Convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8f8oNiykSHQ-",
        "outputId": "73335f67-8c35-46dd-927c-3de8cec11161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " For data_topic_1 :\n",
            "Only shows Wmm\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " For data_topic_2 :\n",
            "Only shows Wmm\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " For data_combine :\n",
            "Only shows Wmm\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = [\n",
        "    # r'$W(t)^{onetoken}$',\n",
        "    r'$W(\\tau)^{mm}$',\n",
        "    r'$W(\\tau)$',\n",
        "]\n",
        "\n",
        "for data in training_datasets:\n",
        "    print('\\n\\n For', data, ':')\n",
        "    show_corr(ITN, dlist, corr_list_values[data], wmm = True, labels = labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
